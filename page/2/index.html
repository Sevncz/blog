<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto+Slab:300,300italic,400,400italic,700,700italic|PT+Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.1/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"sevncz.xyz","root":"/","images":"/images","scheme":"Pisces","version":"8.1.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}};
  </script>
<meta name="description" content="努力赚钱">
<meta property="og:type" content="website">
<meta property="og:title" content="Sevncz&#39;s Blog">
<meta property="og:url" content="http://sevncz.xyz/page/2/index.html">
<meta property="og:site_name" content="Sevncz&#39;s Blog">
<meta property="og:description" content="努力赚钱">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="sevncz">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://sevncz.xyz/page/2/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>
<title>Sevncz's Blog</title>
  



  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Sevncz's Blog</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <section class="post-toc-wrap sidebar-panel">
        </section>
        <!--/noindex-->

        <section class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="sevncz"
      src="/images/IMG_1169.JPG">
  <p class="site-author-name" itemprop="name">sevncz</p>
  <div class="site-description" itemprop="description">努力赚钱</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">17</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/Sevncz" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Sevncz" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



        </section>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://sevncz.xyz/2020/12/15/Hive%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%8F%8A%E4%BC%98%E5%8C%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/IMG_1169.JPG">
      <meta itemprop="name" content="sevncz">
      <meta itemprop="description" content="努力赚钱">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sevncz's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/12/15/Hive%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%8F%8A%E4%BC%98%E5%8C%96/" class="post-title-link" itemprop="url">Hive文件存储及优化</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-12-15 11:48:56" itemprop="dateCreated datePublished" datetime="2020-12-15T11:48:56+08:00">2020-12-15</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2020-12-22 22:40:15" itemprop="dateModified" datetime="2020-12-22T22:40:15+08:00">2020-12-22</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>最近在做大数据项目上线准备，需要知道Hive性能消耗情况，而我们数据仓库在建设使用的过程中，主要消耗的资源包含：CPU、MEMORY、DISK三部分。</p>
<p>数据仓库在计算过程中主要消耗CPU和Memory资源，当然也会消耗一些DISK资源用来存储计算过程中的临时结果。但是主要优化的方向，还是降低CPU和MEMORY的消耗，这方面主要依赖于模型设计的合理性，所以在模型设计阶段增加模型设计review的步骤，保证模型设计的合理性。</p>
<p>数据仓库在数据的存储阶段主要消耗MEMORY和DISK资源。memory资源主要是在NameNode存储文件信息的时候消耗掉；DISK在存储数据的时候消耗掉。在这个阶段需要严格控制HIVE表的的定义，来降低资源的消耗。</p>
<p>本次主要探讨是数据仓库在数据存储阶段对资源消耗的优化，下面将通过2个方面展开，分别是：数据仓库如何配置，可以实现数据压缩，降低数据的存储量，达到减少对DISK的消耗；数仓表如何设计，可以降低文件信息存储量，达到减少对MEMORY的消耗。</p>
<h2 id="小文件问题"><a href="#小文件问题" class="headerlink" title="小文件问题"></a>小文件问题</h2><p>Hive的数据最终是存储在HDFS上，HDFS的NameNode会保存文件的元数据，为了提高响应速度，NameNode在启动的时候会将这些元数据加载到内存，而HDFS中的每一个文件、目录及文件块，在NameNode内存都会记录，每一条信息大约占用150字节的内存空间。如果HDFS 上存在大量的小文件（这里说的小文件是指文件大小要比一个 HDFS 块大小(在 Hadoop1.x 的时候默认块大小64M，可以通过 dfs.blocksize 来设置；但是到了 Hadoop 2.x 的时候默认块大小为128MB了，可以通过 dfs.block.size 设置) 小得多的文件）至少会产生以下几个负面影响：</p>
<ul>
<li>大量的小文件会占用大量的NameNode内存，一个元数据对象大约占用150个字节，一千万文件及分块就大约 会占用3G的内存空间；</li>
<li>如果使用MapReduce任务来处理这些小文件，因为每一个Map会处理一个HDFS Block，这会导致程序需要启动大量的Map来处理这些小文件，虽然这些小文件总的大小不算很大，却占用了集群的大量资源。</li>
</ul>
<h2 id="Hive小文件产生的原因"><a href="#Hive小文件产生的原因" class="headerlink" title="Hive小文件产生的原因"></a>Hive小文件产生的原因</h2><ul>
<li>MapReduce任务产生：我们使用 Hive 查询一张含有海量数据的表，然后存储在另外一张表中，而这个查询只有简单的过滤条件（比如 select * from iteblog where from = ‘hadoop’），这种情况只会启动大量的 Map 来处理，这种情况可能会产生大量的小文件。也可能 Reduce 设置不合理，产生大量的小文件；</li>
<li>Hive统计汇总表，越是上层的表汇总程度就越高，数据量也就越小，而且这些表通常会有日期分区，随着时间的推移，HDFS的文件数目就会逐步增加；</li>
</ul>
<h2 id="小文件问题解决"><a href="#小文件问题解决" class="headerlink" title="小文件问题解决"></a>小文件问题解决</h2><ul>
<li><p>输入合并。即在map前合并小文件。</p>
</li>
<li><p>输出合并。即在输出结果的时候合并小文件。</p>
</li>
</ul>
<h3 id="1-配置Map输入合并"><a href="#1-配置Map输入合并" class="headerlink" title="1. 配置Map输入合并"></a>1. 配置Map输入合并</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-- 每个Map最大输入大小，决定合并后的文件数</span><br><span class="line">set mapred.max.split.size=256000000;</span><br><span class="line">-- 一个节点上split的至少的大小 ，决定了多个data node上的文件是否需要合并</span><br><span class="line">set mapred.min.split.size.per.node=100000000;</span><br><span class="line">-- 一个交换机下split的至少的大小，决定了多个交换机上的文件是否需要合并</span><br><span class="line">set mapred.min.split.size.per.rack=100000000;</span><br><span class="line">-- 执行Map前进行小文件合并</span><br><span class="line">set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;</span><br></pre></td></tr></table></figure>

<h3 id="2-配置Hive结果合并"><a href="#2-配置Hive结果合并" class="headerlink" title="2. 配置Hive结果合并"></a>2. 配置Hive结果合并</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">set hive.merge.mapfiles = true #在Map-only的任务结束时合并小文件</span><br><span class="line">set hive.merge.mapredfiles = true #在Map-Reduce的任务结束时合并小文件</span><br><span class="line">set hive.merge.size.per.task = 256*1000*1000 #合并文件的大小</span><br><span class="line">set hive.merge.smallfiles.avgsize=16000000 #当输出文件的平均大小小于该值时，启动一个独立的map-reduce任务进行文件merge</span><br></pre></td></tr></table></figure>

<p>hive在对结果文件进行合并时会执行一个额外的map-only脚本，mapper的数量是文件总大小除以size.per.task参数所得的值，触发合并的条件是：根据查询类型不同，相应的mapfiles/mapredfiles参数需要打开；结果文件的平均大小需要大于avgsize参数的值。</p>
<h3 id="3-压缩文件的处理"><a href="#3-压缩文件的处理" class="headerlink" title="3. 压缩文件的处理"></a>3. 压缩文件的处理</h3><p>对于输出结果为压缩文件形式存储的情况，要解决小文件问题，如果在map输入前合并，对输出的文件存储格式并没有限制。但是如果使用输出合并，则必须配合SequenceFile来存储，否则无法进行合并，以下是实例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> mapred.output.compression.type=<span class="keyword">BLOCK</span>;</span><br><span class="line"><span class="keyword">set</span> hive.exec.compress.output= <span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> mapred.output.compression.codec=org.apache.hadoop.io.compress.LzoCodec;</span><br><span class="line"><span class="keyword">set</span> hive.merge.smallfiles.avgsize=<span class="number">100000000</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> dw_stage.zj_small;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> dw_stage.zj_small</span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> SEQUENCEFILE</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> *</span><br><span class="line"><span class="keyword">from</span> dw_db.dw_soj_imp_dtl</span><br><span class="line"><span class="keyword">where</span> log_dt = <span class="string">&#x27;2014-04-14&#x27;</span></span><br><span class="line"><span class="keyword">and</span> paid <span class="keyword">like</span> <span class="string">&#x27;%baidu%&#x27;</span> ;</span><br></pre></td></tr></table></figure>

<h3 id="4-使用HAR归档文件"><a href="#4-使用HAR归档文件" class="headerlink" title="4. 使用HAR归档文件"></a>4. 使用HAR归档文件</h3><p>Hadoop的归档文件格式也是解决小文件问题的方式之一。而且hive提供了原生支持：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.archive.enabled= <span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> hive.archive.har.parentdir.settable= <span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> har.partfile.size=<span class="number">1099511627776</span>;</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> srcpart <span class="keyword">ARCHIVE</span> <span class="keyword">PARTITION</span>(ds= <span class="string">&#x27;2008-04-08&#x27;</span>, hr= <span class="string">&#x27;12&#x27;</span> );</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> srcpart UNARCHIVE <span class="keyword">PARTITION</span>(ds= <span class="string">&#x27;2008-04-08&#x27;</span>, hr= <span class="string">&#x27;12&#x27;</span> );</span><br></pre></td></tr></table></figure>

<p>如果使用的不是分区表，则可以创建成外部表，并使用har://协议来指定路径。</p>
<h2 id="文件类型"><a href="#文件类型" class="headerlink" title="文件类型"></a>文件类型</h2><p>hive在存储数据时支持通过不同的文件类型来组织，并且为了节省相应的存储资源，也提供了多种类型的压缩算法，供用户选择。只要是配置正确的文件类型和压缩类型，hive都可以按预期读取并解析数据，不影响上层HQL语句的使用。例如：SequenceFile本身的结构已经设计了对内容进行压缩，所以对于SequenceFile文件的压缩，并不是先生成SequenceFile文件，再对文件进行压缩；而是生成SequenceFile文件时，就对其中的内容字段进行压缩。最终压缩后，对外仍然体现为一个SequenceFile。RCFile、ORCFile、Parquet、Avro对于压缩的处理方式与SequenceFile相同。</p>
<p>hive支持的文件类型有：TextFile、SequenceFile、RCFile、ORCFile、Parquet、Avro。</p>
<table>
  <tr>
    <th>存储格式</td>
    <th>存储方式</td>
    <th>特点</td>
  </tr>
  <tr>
    <td rowspan="5">TextFile</td>
    <td rowspan="5">行存储</td>
    <td>存储空间消耗比较大</td>
  </tr>
  <tr>
    <td>压缩的text无法分割和合并</td>
  </tr>
  <tr>
    <td>查询效率低</td>
  </tr>
  <tr>
    <td>可以直接存储</td>
  </tr>
  <tr>
    <td>加载数据速度最高</td>
  </tr>
  <tr>
    <td rowspan="4">SequenceFile</td>
    <td rowspan="4">行存储</td>
    <td>存储空间消耗最大</td>
  </tr>
  <tr>
    <td>压缩的文件可以分割和合并</td>
  </tr>
  <tr>
    <td>查询效率高</td>
  </tr>
  <tr>
    <td>需要通过text文件转化来加载</td>
  </tr>
  <tr>
    <td rowspan="8">RCFile</td>
    <td rowspan="8">数据按行分块，每块按列存储</td>
    <td>存储空间最小</td>
  </tr>
  <tr>
    <td>查询效率最高</td>
  </tr>
  <tr>
    <td>需要通过text文件转化来加载</td>
  </tr>
  <tr>
    <td>加载的速度最低</td>
  </tr>
  <tr>
    <td>压缩快，快速列存储</td>
  </tr>
  <tr>
    <td>读记录尽量设计到的block最少</td>
  </tr>
  <tr>
    <td>读取需要的列只需要读取每个row group的头部定义</td>
  </tr>
  <tr>
    <td>读取全量数据的操作性能可能比sequencefile没有明显的优势</td>
  </tr>
  <tr>
    <td rowspan="2">ORCFile</td>
    <td rowspan="2">数据按行分块，每块按列存储</td>
    <td>压缩快，快速列存储</td>
  </tr>
  <tr>
    <td>效率比RCFile高，是RCFile的改良版</td>
  </tr>
  <tr>
    <td rowspan="4">Parquet</td>
    <td rowspan="4">列存储</td>
    <td>相对于PRC，Parquet压缩比较低</td>
  </tr>
  <tr>
    <td>查询效率比较低</td>
  </tr>
  <tr>
    <td>不支持update、insert和ACID</td>
  </tr>
  <tr>
    <td>支持Impala查询引擎</td>
  </tr>
  <tr>
    <td rowspan="5">Avro</td>
    <td rowspan="5">二进制存储</td>
    <td>基于列(在列中存储数据):用于数据存储是包含大量读取操作的优化分析工作负载</td>
  </tr>
  <tr>
    <td>与Snappy的压缩压缩率高(75%)</td>
  </tr>
  <tr>
    <td>只需要列将获取/读(减少磁盘I / O)</td>
  </tr>
  <tr>
    <td>可以使用Avro API和Avro读写模式</td>
  </tr>
  <tr>
    <td>支持谓词下推(减少磁盘I / O的成本)</td>
  </tr>
</table>

<h2 id="压缩算法"><a href="#压缩算法" class="headerlink" title="压缩算法"></a>压缩算法</h2><p>待补充</p>
<h2 id="表分区优化"><a href="#表分区优化" class="headerlink" title="表分区优化"></a>表分区优化</h2><ul>
<li>对于统计数据表、数据量不大的基础表、业务上无累计快照和周期性快照要求的数据表，尽可能的不创建分区，而采用数据合并回写的方式解决；</li>
<li>对于一些数据量大的表，如果需要创建分区，提高插叙过程中数据的加载速度，尽可能的只做天级分区。而对于原始数据，这种特大的数据量的，可以采用小时分区。对于月分区，坚决去掉。</li>
<li>对于一些周期快照和累计快照的表，我们尽可能只创建日分区。</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://sevncz.xyz/2020/12/15/Redis%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/IMG_1169.JPG">
      <meta itemprop="name" content="sevncz">
      <meta itemprop="description" content="努力赚钱">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sevncz's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/12/15/Redis%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" class="post-title-link" itemprop="url">Redis底层数据结构</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-12-15 10:01:35" itemprop="dateCreated datePublished" datetime="2020-12-15T10:01:35+08:00">2020-12-15</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2020-12-22 22:39:51" itemprop="dateModified" datetime="2020-12-22T22:39:51+08:00">2020-12-22</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Redis/" itemprop="url" rel="index"><span itemprop="name">Redis</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>一提到 Redis，我们的脑子里马上就会出现一个词：“快”，这里的快，体现在Redis接收到一个键值对操作后，能以微秒级别的速度找到数据，并快速完成操作。那，为什么这么快呢？一方面，这是因为它是内存数据库，所有的操作都是在内存上完成，内存的访问速度本身就很快。另一方面，这要归功于它的数据结构，这是因为，键值对是按一定的数据结构来阻止的，操作键值对最终就是对数据结构进行增删改查操作，所以高效的数据结构是Redis快速处理数据的基础。</p>
<h2 id="六种底层数据结构"><a href="#六种底层数据结构" class="headerlink" title="六种底层数据结构"></a>六种底层数据结构</h2><p>Redis的底层数据结构一共有6中，分别是简单动态字符串、双向链表、压缩列表、哈希表、跳表和整数数组。</p>
<p>Redis的数据类型和底层数据结构的关系：</p>
<ul>
<li>String：简单动态字符串</li>
<li>List：双向链表、压缩列表</li>
<li>Hash：压缩列表、哈希表</li>
<li>Sorted Set：压缩列表、跳表</li>
<li>Set：哈希表、整数数组</li>
</ul>
<p>这里，我们会遇到如下几个问题：</p>
<ol>
<li>这些数据结构都是值的底层实现，键和值本身之间用什么结构组织？</li>
<li>为什么集合类型有那么多的底层结构，它们都是怎么组织数据的，都很快吗？</li>
<li>什么是简单动态字符串，和常用的字符串是一回事吗？</li>
</ol>
<h2 id="键和值用什么结构组织"><a href="#键和值用什么结构组织" class="headerlink" title="键和值用什么结构组织"></a>键和值用什么结构组织</h2><p>为了实现从键到值的快速访问，Redis 使用了一个哈希表来保存所有的键值对。</p>
<p>一个哈希表，其实就是一个数组，数组的每个元素称为一个哈希桶。所以，我们常说一个哈希表是由多个哈希桶组成，每个哈希桶中保存了键值对数据。哈希桶中并不存键值对本身，而是存键值对指针。因为这个哈希表保存了所有的键值对，所以，我也把它称为全局哈希表。哈希表的好处就是我们能以O(1)的时间复杂度来快速查找到键值对 （我们只需要计算键的哈希值，就可以知道它所对应的哈希桶位置，然后就可以访问相应的 entry 元素）。</p>
<p>当哈希表写入大量的数据之后，就会产生哈希冲突和rehash可能带来的操作阻塞。</p>
<h2 id="哈希冲突问题"><a href="#哈希冲突问题" class="headerlink" title="哈希冲突问题"></a>哈希冲突问题</h2><p>当你往哈希表中写入更多数据时，哈希冲突是不可避免的问题。这里的哈希冲突，也就是指，两个 key 的哈希值和哈希桶计算对应关系时，正好落在了同一个哈希桶中。</p>
<p>Redis 解决哈希冲突的方式，就是链式哈希。链式哈希，就是指同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接。</p>
<h2 id="rehash"><a href="#rehash" class="headerlink" title="rehash"></a>rehash</h2><p>随着哈希表里写入的数据越来越多，哈希冲突可能也会越来越多，这就会导致某些哈希冲突链过长，进而导致这个链上的元素查找耗时长，效率降低。这时，Redis会对哈希表做rehash操作。rehash也就是增加现有的哈希桶数量，让逐渐增多的entry元素能在更多的桶之间分散保存，减少单个桶的元素数量，从而减少单个桶的冲突。</p>
<p>具体做法：为了使rehash操作更高效，Redis默认使用了两个全局哈希表：哈希表1和哈希表2。一开始，当你插入数据时，默认会使用哈希表1，此时的哈希表2并没有分配空间，随着数据逐步增多，Redis开始进行rehash，这个过程分为3步：</p>
<ol>
<li>给哈希表2分配更多的空间，例如时当前哈希表1大小的2倍；</li>
<li>把哈希表1中的数据重新映射并拷贝到哈希表2中；</li>
<li>释放哈希表1的空间。</li>
</ol>
<p>到此，就可以从哈希表 1 切换到哈希表 2，用增大的哈希表 2 保存更多数据，而原来的哈希表 1 留作下一次 rehash 扩容备用。</p>
<p>这个过程看似简单，但是第二步涉及到大量的数据拷贝，如果一次性把哈希表1中的数据都迁移完，会造成Redis线程阻塞，无法服务其他请求。</p>
<p>为了避免这个问题，Redis采用了<strong>渐进式rehash</strong>。</p>
<p>简单来说就是第二步拷贝数据时，Redis仍然正常处理客户端请求，每处理一个请求时，从哈希表1中的第一个索引位置开始，顺带着将这个索引位置上的所有entry拷贝到哈希表2中；等处理下一个请求时，再顺带拷贝哈希表1中下一个索引位置的entry。这样就巧妙地把一次性大量拷贝的开销，分摊到了多次处理请求的过程中，避免了耗时操作，保证了数据的快速访问。</p>
<p>对于String类型来说，找到哈希桶就能直接增删改查了，所以哈希表O(1)操作复杂度也就是它的复杂度了。</p>
<p>对于集合类型来说，即使找到哈希桶了，还要在集合中再进一步操作。</p>
<h2 id="集合数据操作"><a href="#集合数据操作" class="headerlink" title="集合数据操作"></a>集合数据操作</h2><p>和 String 类型不同，一个集合类型的值，第一步是通过全局哈希表找到对应的哈希桶位置，第二步是在集合中再增删改查。那么，集合的操作效率和哪些因素相关呢？</p>
<p>首先，与集合的底层数据结构有关。例如，使用哈希表实现的集合，要比使用链表实现的集合访问效率更高。其次，操作效率和这些操作本身的执行特点有关，比如读写一个元素的操作要比读写所有元素的效率高。</p>
<h3 id="有哪些底层数据结构"><a href="#有哪些底层数据结构" class="headerlink" title="有哪些底层数据结构"></a>有哪些底层数据结构</h3><p>集合类型的底层数据结构主要有 5 种：整数数组、双向链表、哈希表、压缩列表和跳表。</p>
<p>哈希表的操作特点如上文所述，整数数组和双向链表也很常见，它们的操作特征都是顺序读写，也就是通过数组下标或者链表的指针逐个元素访问，操作复杂度基本时O(N)，操作效率比较低；</p>
<h4 id="压缩列表"><a href="#压缩列表" class="headerlink" title="压缩列表"></a>压缩列表</h4><p>压缩列表实际上类似于一个数组，数组中的每一个元素都对应保存一个数据。和数组不同的是，压缩列表在表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量和列表中的 entry 个数；压缩列表在表尾还有一个 zlend，表示列表结束。</p>
<p>在压缩列表中，如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是 O(1)。而查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是 O(N) 了。</p>
<h4 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h4><p>有序链表只能逐一查找元素，导致操作起来非常缓慢，于是就出现了跳表。具体来说，跳表在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位，</p>
<h2 id="不同的操作复杂度"><a href="#不同的操作复杂度" class="headerlink" title="不同的操作复杂度"></a>不同的操作复杂度</h2><p>集合类型的操作类型很多，有读写单个集合元素的，例如 HGET、HSET，也有操作多个元素的，例如 SADD，还有对整个集合进行遍历操作的，例如 SMEMBERS。这么多操作，它们的复杂度也各不相同。而复杂度的高低又是我们选择集合类型的重要依据。</p>
<ul>
<li>单元素操作是基础；</li>
<li>范围操作非常耗时；</li>
<li>统计操作通常高效；</li>
<li>例外情况只有几个。</li>
</ul>
<p>第一，单元素操作，是指每一种集合类型对单个数据实现的增删改查操作。例如，Hash 类型的 HGET、HSET 和 HDEL，Set 类型的 SADD、SREM、SRANDMEMBER 等。这些操作的复杂度由集合采用的数据结构决定，例如，HGET、HSET 和 HDEL 是对哈希表做操作，所以它们的复杂度都是 O(1)；Set 类型用哈希表作为底层数据结构时，它的 SADD、SREM、SRANDMEMBER 复杂度也是 O(1)。</p>
<p>这里，有个地方你需要注意一下，集合类型支持同时对多个元素进行增删改查，例如 Hash 类型的 HMGET 和 HMSET，Set 类型的 SADD 也支持同时增加多个元素。此时，这些操作的复杂度，就是由单个元素操作复杂度和元素个数决定的。例如，HMSET 增加 M 个元素时，复杂度就从 O(1) 变成 O(M) 了。</p>
<p>第二，范围操作，是指集合类型中的遍历操作，可以返回集合中的所有数据，比如 Hash 类型的 HGETALL 和 Set 类型的 SMEMBERS，或者返回一个范围内的部分数据，比如 List 类型的 LRANGE 和 ZSet 类型的 ZRANGE。这类操作的复杂度一般是 O(N)，比较耗时，我们应该尽量避免。不过，Redis 从 2.8 版本开始提供了 SCAN 系列操作（包括 HSCAN，SSCAN 和 ZSCAN），这类操作实现了渐进式遍历，每次只返回有限数量的数据。这样一来，相比于 HGETALL、SMEMBERS 这类操作来说，就避免了一次性返回所有元素而导致的 Redis 阻塞。</p>
<p>第三，统计操作，是指集合类型对集合中所有元素个数的记录，例如 LLEN 和 SCARD。这类操作复杂度只有 O(1)，这是因为当集合类型采用压缩列表、双向链表、整数数组这些数据结构时，这些结构中专门记录了元素的个数统计，因此可以高效地完成相关操作。</p>
<p>第四，例外情况，是指某些数据结构的特殊记录，例如压缩列表和双向链表都会记录表头和表尾的偏移量。这样一来，对于 List 类型的 LPOP、RPOP、LPUSH、RPUSH 这四个操作来说，它们是在列表的头尾增删元素，这就可以通过偏移量直接定位，所以它们的复杂度也只有 O(1)，可以实现快速操作。</p>
<h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>整数数组和压缩列表在查找时间复杂度方面并没有很大的优势，那为什么 Redis 还会把它们作为底层数据结构呢？</p>
<p>1、内存利用率，数组和压缩列表都是非常紧凑的数据结构，它比链表占用的内存要更少。Redis是内存数据库，大量数据存到内存中，此时需要做尽可能的优化，提高内存的利用率。 </p>
<p>2、数组对CPU高速缓存支持更友好，所以Redis在设计时，集合数据元素较少情况下，默认采用内存紧凑排列的方式存储，同时利用CPU高速缓存不会降低访问速度。当数据元素超过设定阈值后，避免查询时间复杂度太高，转为哈希和跳表数据结构存储，保证查询效率。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://sevncz.xyz/2020/12/14/Spark%20Streaming%E8%BF%90%E8%A1%8C%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/IMG_1169.JPG">
      <meta itemprop="name" content="sevncz">
      <meta itemprop="description" content="努力赚钱">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sevncz's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/12/14/Spark%20Streaming%E8%BF%90%E8%A1%8C%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/" class="post-title-link" itemprop="url">Spark Streaming运行的基本原理</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-12-14 13:43:00" itemprop="dateCreated datePublished" datetime="2020-12-14T13:43:00+08:00">2020-12-14</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2020-12-22 22:40:58" itemprop="dateModified" datetime="2020-12-22T22:40:58+08:00">2020-12-22</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Spark Streaming运行时由Driver和Executor相互协调完成。</p>
<p>Driver端创建<strong>StreamingContent</strong>，其中包括了<strong>DStreamGraph</strong>和<strong>JobSchedule</strong>，它又包括了<strong>ReceiverTracker</strong>和<strong>JobGenerator</strong>），Driver主要负责生成调度job、与execuor进行交互、指导工作。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://sevncz.xyz/2020/12/14/%E8%AE%B0%E4%B8%80%E6%AC%A1Mac%E5%A4%84%E7%90%86%E6%96%87%E4%BB%B6%E6%97%A0%E6%B3%95%E5%88%A0%E9%99%A4%E6%93%8D%E4%BD%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/IMG_1169.JPG">
      <meta itemprop="name" content="sevncz">
      <meta itemprop="description" content="努力赚钱">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sevncz's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/12/14/%E8%AE%B0%E4%B8%80%E6%AC%A1Mac%E5%A4%84%E7%90%86%E6%96%87%E4%BB%B6%E6%97%A0%E6%B3%95%E5%88%A0%E9%99%A4%E6%93%8D%E4%BD%9C/" class="post-title-link" itemprop="url">记一次Mac处理文件无法删除操作</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-12-14 10:34:43" itemprop="dateCreated datePublished" datetime="2020-12-14T10:34:43+08:00">2020-12-14</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2020-12-22 22:40:42" itemprop="dateModified" datetime="2020-12-22T22:40:42+08:00">2020-12-22</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Mac/" itemprop="url" rel="index"><span itemprop="name">Mac</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="处理流程"><a href="#处理流程" class="headerlink" title="处理流程"></a>处理流程</h2><p>安装了公司的安全上网软件，但是无法卸载和删除。</p>
<p>执行rm -rf无法删除</p>
<img src="/2020/12/14/%E8%AE%B0%E4%B8%80%E6%AC%A1Mac%E5%A4%84%E7%90%86%E6%96%87%E4%BB%B6%E6%97%A0%E6%B3%95%E5%88%A0%E9%99%A4%E6%93%8D%E4%BD%9C/image-20201214103807333.png" class="">

<p><code>ls -lO</code>查看权限</p>
<img src="/2020/12/14/%E8%AE%B0%E4%B8%80%E6%AC%A1Mac%E5%A4%84%E7%90%86%E6%96%87%E4%BB%B6%E6%97%A0%E6%B3%95%E5%88%A0%E9%99%A4%E6%93%8D%E4%BD%9C/image-20201214103914978.png" class="">

<p>需要清理这两个标记</p>
<p>执行：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo chflags -R nohidden [文件夹名称]</span><br><span class="line">sudo chflags -R noschg [文件夹名称]</span><br><span class="line">sudo chmod -R +w [文件夹名称]</span><br><span class="line">sudo chmod -R +r [文件夹名称]</span><br></pre></td></tr></table></figure>

<p>最后</p>
<img src="/2020/12/14/%E8%AE%B0%E4%B8%80%E6%AC%A1Mac%E5%A4%84%E7%90%86%E6%96%87%E4%BB%B6%E6%97%A0%E6%B3%95%E5%88%A0%E9%99%A4%E6%93%8D%E4%BD%9C/image-20201214104224717.png" class="">

<h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><p><code>ls</code>的<code>-O</code>选项，可以列出文件的file flag。</p>
<h3 id="File-Flag"><a href="#File-Flag" class="headerlink" title="File Flag"></a>File Flag</h3><p>File flag是在BSD Unix中的概念，跟Linux系统中的attr是差不多的一个概念，是文件的一些标志位来存放文件的某些属性。chflags就是来修改这个file flag的。这个文件属性是跟文件系统相关的，所以这个命令在不同的文件系统上的支持程度不一样，体现在某一些flag在一些特定的文件系统上没有。</p>
<h3 id="常见的几个属性"><a href="#常见的几个属性" class="headerlink" title="常见的几个属性"></a>常见的几个属性</h3><table>
<thead>
<tr>
<th align="left">属性</th>
<th align="left">ls中显示</th>
<th align="left">chflags中使用</th>
<th align="left">文件所有者能否修改</th>
<th align="left">详述</th>
</tr>
</thead>
<tbody><tr>
<td align="left">隐藏</td>
<td align="left">hidden</td>
<td align="left">hidden</td>
<td align="left">能</td>
<td align="left">设置以后在GUI上看不到，ls依然可以看到d</td>
</tr>
<tr>
<td align="left">系统级只能添加</td>
<td align="left">sappnd</td>
<td align="left">sappnd, sappend</td>
<td align="left">否</td>
<td align="left">设置以后此文件不能够截断或者复写(overwrite)，只能通过append模式添加内容</td>
</tr>
<tr>
<td align="left">用户级只能添加</td>
<td align="left">uappnd</td>
<td align="left">uappnd, uappend</td>
<td align="left">能</td>
<td align="left">设置以后此文件不能够截断或者复写(overwrite)，只能通过append模式添加内容</td>
</tr>
<tr>
<td align="left">系统级只读</td>
<td align="left">schg</td>
<td align="left">schg, schange, simmutable</td>
<td align="left">否</td>
<td align="left">不能够重命名、移动、删除、更改内容</td>
</tr>
<tr>
<td align="left">用户级只读</td>
<td align="left">uchg</td>
<td align="left">uchg, uchange, uimmutable</td>
<td align="left">能</td>
<td align="left">不能够更改内容</td>
</tr>
</tbody></table>
<h3 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h3><p><code>chflags [-fhv] [-R [-H | -L | -P]] flags file</code></p>
<h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><p><strong>为一个文件添加一个属性</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chflags uchg file</span><br></pre></td></tr></table></figure>

<p><strong>为一个文件删除一个属性</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chflags nouchg file</span><br></pre></td></tr></table></figure>

<p>在属性名字前面添加no就可以将属性删除，如果这个属性本身已no开头（比如nodump）则去掉no。</p>
<p><strong>将文件夹及其文件夹下所有文件属性进行修改</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chflags -R uchg directory</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://sevncz.xyz/2020/12/08/Spark%20SQL%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/IMG_1169.JPG">
      <meta itemprop="name" content="sevncz">
      <meta itemprop="description" content="努力赚钱">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sevncz's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/12/08/Spark%20SQL%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" class="post-title-link" itemprop="url">Spark SQL 源码分析</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-12-08 12:22:00" itemprop="dateCreated datePublished" datetime="2020-12-08T12:22:00+08:00">2020-12-08</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2020-12-22 22:41:02" itemprop="dateModified" datetime="2020-12-22T22:41:02+08:00">2020-12-22</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="入口"><a href="#入口" class="headerlink" title="入口"></a>入口</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">SparkSession</span> -&gt;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sql</span></span>(sqlText: <span class="type">String</span>): <span class="type">DataFrame</span> = &#123;</span><br><span class="line"></span><br><span class="line"> <span class="type">Dataset</span>.ofRows(self, sessionState.sqlParser.parsePlan(sqlText))</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Parser"><a href="#Parser" class="headerlink" title="Parser"></a>Parser</h2><p>parsePlan方法会返回一个LogicalPlan对象；</p>
<p>第一步，利用 antlr4 生成的 SqlBaseLexer【val lexer = new SqlBaseLexer(new UpperCaseCharStream(CharStreams.fromString(command)))】 对SQL进行词法分析，生成一个CommonTokenStream 对象【val tokenStream = new CommonTokenStream(lexer)】</p>
<p>第二步，利用 antlr4 生成的 SqlBaseParser 【val parser = new SqlBaseParser(tokenStream)】对SQL进行语法分析，得到 Unresolved LogicalPlan</p>
<p>以下均在 QueryExecution 中执行</p>
<h2 id="Analyzer"><a href="#Analyzer" class="headerlink" title="Analyzer"></a>Analyzer</h2><p>Analyzer 持有一个 SessionCatalog 对象的引用</p>
<p>Analyzer 继承自 RuleExecutor[LogicalPlan]，因此可以对 LogicalPlan 进行转换</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">lazy</span> <span class="keyword">val</span> analyzed: <span class="type">LogicalPlan</span> = &#123;</span><br><span class="line"></span><br><span class="line"> <span class="type">SparkSession</span>.setActiveSession(sparkSession)</span><br><span class="line"></span><br><span class="line"> sparkSession.sessionState.analyzer.executeAndCheck(logical)</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>通过 Catalog 确定每张表对应的字段集、字段类型、数据存储位置，生成Resolved Logical Plan</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">checkAnalysis</span></span>(plan: <span class="type">LogicalPlan</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">case</span> u: <span class="type">UnresolvedRelation</span> =&gt;</span><br><span class="line"></span><br><span class="line">  u.failAnalysis(<span class="string">s&quot;Table or view not found: <span class="subst">$&#123;u.tableIdentifier&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>ResolveRelations</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 关联表</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">lookupTableFromCatalog</span></span>(</span><br><span class="line"></span><br><span class="line">  u: <span class="type">UnresolvedRelation</span>,</span><br><span class="line"></span><br><span class="line">  defaultDatabase: <span class="type">Option</span>[<span class="type">String</span>] = <span class="type">None</span>): <span class="type">LogicalPlan</span> =&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Optimizer"><a href="#Optimizer" class="headerlink" title="Optimizer"></a>Optimizer</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">lazy</span> <span class="keyword">val</span> optimizedPlan: <span class="type">LogicalPlan</span> = sparkSession.sessionState.optimizer.execute(withCachedData)</span><br></pre></td></tr></table></figure>

<p>逻辑优化器，会进行谓词下推，列值裁剪，常量折叠，谓词合并等等一系列逻辑优化</p>
<p>根据预先定义好的规则对 Resolved Logical Plan 进行优化并生成 Optimized Logical Plan</p>
<h2 id="SparkPlanner"><a href="#SparkPlanner" class="headerlink" title="SparkPlanner"></a>SparkPlanner</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">lazy</span> <span class="keyword">val</span> sparkPlan: <span class="type">SparkPlan</span> = &#123;</span><br><span class="line"></span><br><span class="line"> <span class="type">SparkSession</span>.setActiveSession(sparkSession)</span><br><span class="line"></span><br><span class="line"> <span class="comment">// <span class="doctag">TODO:</span> We use next(), i.e. take the first plan returned by the planner, here for now,</span></span><br><span class="line"></span><br><span class="line"> <span class="comment">//    but we will implement to choose the best plan.</span></span><br><span class="line"></span><br><span class="line"> planner.plan(<span class="type">ReturnAnswer</span>(optimizedPlan)).next()</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>把 Logical Plan 转变为 Physical Plan</p>
<h2 id="执行-Physical-Plan"><a href="#执行-Physical-Plan" class="headerlink" title="执行 Physical Plan"></a>执行 Physical Plan</h2><p>lazy val executedPlan: SparkPlan = prepareForExecution(sparkPlan)</p>
<p><strong>转成RDD</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** Internal version of the RDD. Avoids copies and has no schema */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">lazy</span> <span class="keyword">val</span> toRdd: <span class="type">RDD</span>[<span class="type">InternalRow</span>] = &#123;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">if</span> (sparkSession.sessionState.conf.getConf(<span class="type">SQLConf</span>.<span class="type">USE_CONF_ON_RDD_OPERATION</span>)) &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">new</span> <span class="type">SQLExecutionRDD</span>(executedPlan.execute(), sparkSession.sessionState.conf)</span><br><span class="line"></span><br><span class="line"> &#125; <span class="keyword">else</span> &#123;</span><br><span class="line"></span><br><span class="line">  executedPlan.execute()</span><br><span class="line"></span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>


<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">sevncz@xyz</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  







  






</body>
</html>
