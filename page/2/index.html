<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto+Slab:300,300italic,400,400italic,700,700italic|PT+Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.1/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"sevncz.xyz","root":"/","images":"/images","scheme":"Pisces","version":"8.1.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}};
  </script>
<meta name="description" content="努力赚钱">
<meta property="og:type" content="website">
<meta property="og:title" content="Sevncz&#39;s Blog">
<meta property="og:url" content="http://sevncz.xyz/page/2/index.html">
<meta property="og:site_name" content="Sevncz&#39;s Blog">
<meta property="og:description" content="努力赚钱">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="sevncz">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://sevncz.xyz/page/2/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>
<title>Sevncz's Blog</title>
  



  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Sevncz's Blog</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <section class="post-toc-wrap sidebar-panel">
        </section>
        <!--/noindex-->

        <section class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="sevncz"
      src="/images/IMG_1169.JPG">
  <p class="site-author-name" itemprop="name">sevncz</p>
  <div class="site-description" itemprop="description">努力赚钱</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">14</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/Sevncz" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Sevncz" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



        </section>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://sevncz.xyz/2020/12/14/%E8%AE%B0%E4%B8%80%E6%AC%A1Mac%E5%A4%84%E7%90%86%E6%96%87%E4%BB%B6%E6%97%A0%E6%B3%95%E5%88%A0%E9%99%A4%E6%93%8D%E4%BD%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/IMG_1169.JPG">
      <meta itemprop="name" content="sevncz">
      <meta itemprop="description" content="努力赚钱">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sevncz's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/12/14/%E8%AE%B0%E4%B8%80%E6%AC%A1Mac%E5%A4%84%E7%90%86%E6%96%87%E4%BB%B6%E6%97%A0%E6%B3%95%E5%88%A0%E9%99%A4%E6%93%8D%E4%BD%9C/" class="post-title-link" itemprop="url">记一次Mac处理文件无法删除操作</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2020-12-14 10:34:43 / 修改时间：11:08:52" itemprop="dateCreated datePublished" datetime="2020-12-14T10:34:43+08:00">2020-12-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/server/" itemprop="url" rel="index"><span itemprop="name">server</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="处理流程"><a href="#处理流程" class="headerlink" title="处理流程"></a>处理流程</h2><p>安装了公司的安全上网软件，但是无法卸载和删除。</p>
<p>执行rm -rf无法删除</p>
<img src="/2020/12/14/%E8%AE%B0%E4%B8%80%E6%AC%A1Mac%E5%A4%84%E7%90%86%E6%96%87%E4%BB%B6%E6%97%A0%E6%B3%95%E5%88%A0%E9%99%A4%E6%93%8D%E4%BD%9C/image-20201214103807333.png" class="">

<p><code>ls -lO</code>查看权限</p>
<img src="/2020/12/14/%E8%AE%B0%E4%B8%80%E6%AC%A1Mac%E5%A4%84%E7%90%86%E6%96%87%E4%BB%B6%E6%97%A0%E6%B3%95%E5%88%A0%E9%99%A4%E6%93%8D%E4%BD%9C/image-20201214103914978.png" class="">

<p>需要清理这两个标记</p>
<p>执行：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo chflags -R nohidden [文件夹名称]</span><br><span class="line">sudo chflags -R noschg [文件夹名称]</span><br><span class="line">sudo chmod -R +w [文件夹名称]</span><br><span class="line">sudo chmod -R +r [文件夹名称]</span><br></pre></td></tr></table></figure>

<p>最后</p>
<img src="/2020/12/14/%E8%AE%B0%E4%B8%80%E6%AC%A1Mac%E5%A4%84%E7%90%86%E6%96%87%E4%BB%B6%E6%97%A0%E6%B3%95%E5%88%A0%E9%99%A4%E6%93%8D%E4%BD%9C/image-20201214104224717.png" class="">

<h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><p><code>ls</code>的<code>-O</code>选项，可以列出文件的file flag。</p>
<h3 id="File-Flag"><a href="#File-Flag" class="headerlink" title="File Flag"></a>File Flag</h3><p>File flag是在BSD Unix中的概念，跟Linux系统中的attr是差不多的一个概念，是文件的一些标志位来存放文件的某些属性。chflags就是来修改这个file flag的。这个文件属性是跟文件系统相关的，所以这个命令在不同的文件系统上的支持程度不一样，体现在某一些flag在一些特定的文件系统上没有。</p>
<h3 id="常见的几个属性"><a href="#常见的几个属性" class="headerlink" title="常见的几个属性"></a>常见的几个属性</h3><table>
<thead>
<tr>
<th align="left">属性</th>
<th align="left">ls中显示</th>
<th align="left">chflags中使用</th>
<th align="left">文件所有者能否修改</th>
<th align="left">详述</th>
</tr>
</thead>
<tbody><tr>
<td align="left">隐藏</td>
<td align="left">hidden</td>
<td align="left">hidden</td>
<td align="left">能</td>
<td align="left">设置以后在GUI上看不到，ls依然可以看到d</td>
</tr>
<tr>
<td align="left">系统级只能添加</td>
<td align="left">sappnd</td>
<td align="left">sappnd, sappend</td>
<td align="left">否</td>
<td align="left">设置以后此文件不能够截断或者复写(overwrite)，只能通过append模式添加内容</td>
</tr>
<tr>
<td align="left">用户级只能添加</td>
<td align="left">uappnd</td>
<td align="left">uappnd, uappend</td>
<td align="left">能</td>
<td align="left">设置以后此文件不能够截断或者复写(overwrite)，只能通过append模式添加内容</td>
</tr>
<tr>
<td align="left">系统级只读</td>
<td align="left">schg</td>
<td align="left">schg, schange, simmutable</td>
<td align="left">否</td>
<td align="left">不能够重命名、移动、删除、更改内容</td>
</tr>
<tr>
<td align="left">用户级只读</td>
<td align="left">uchg</td>
<td align="left">uchg, uchange, uimmutable</td>
<td align="left">能</td>
<td align="left">不能够更改内容</td>
</tr>
</tbody></table>
<h3 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h3><p><code>chflags [-fhv] [-R [-H | -L | -P]] flags file</code></p>
<h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><p><strong>为一个文件添加一个属性</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chflags uchg file</span><br></pre></td></tr></table></figure>

<p><strong>为一个文件删除一个属性</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chflags nouchg file</span><br></pre></td></tr></table></figure>

<p>在属性名字前面添加no就可以将属性删除，如果这个属性本身已no开头（比如nodump）则去掉no。</p>
<p><strong>将文件夹及其文件夹下所有文件属性进行修改</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chflags -R uchg directory</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://sevncz.xyz/2020/12/08/Spark%20SQL%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/IMG_1169.JPG">
      <meta itemprop="name" content="sevncz">
      <meta itemprop="description" content="努力赚钱">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sevncz's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/12/08/Spark%20SQL%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" class="post-title-link" itemprop="url">Spark SQL 源码分析</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-12-08 12:22:00" itemprop="dateCreated datePublished" datetime="2020-12-08T12:22:00+08:00">2020-12-08</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2020-12-11 22:25:19" itemprop="dateModified" datetime="2020-12-11T22:25:19+08:00">2020-12-11</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="入口"><a href="#入口" class="headerlink" title="入口"></a>入口</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">SparkSession</span> -&gt;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sql</span></span>(sqlText: <span class="type">String</span>): <span class="type">DataFrame</span> = &#123;</span><br><span class="line"></span><br><span class="line"> <span class="type">Dataset</span>.ofRows(self, sessionState.sqlParser.parsePlan(sqlText))</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Parser"><a href="#Parser" class="headerlink" title="Parser"></a>Parser</h2><p>parsePlan方法会返回一个LogicalPlan对象；</p>
<p>第一步，利用 antlr4 生成的 SqlBaseLexer【val lexer = new SqlBaseLexer(new UpperCaseCharStream(CharStreams.fromString(command)))】 对SQL进行词法分析，生成一个CommonTokenStream 对象【val tokenStream = new CommonTokenStream(lexer)】</p>
<p>第二步，利用 antlr4 生成的 SqlBaseParser 【val parser = new SqlBaseParser(tokenStream)】对SQL进行语法分析，得到 Unresolved LogicalPlan</p>
<p>以下均在 QueryExecution 中执行</p>
<h2 id="Analyzer"><a href="#Analyzer" class="headerlink" title="Analyzer"></a>Analyzer</h2><p>Analyzer 持有一个 SessionCatalog 对象的引用</p>
<p>Analyzer 继承自 RuleExecutor[LogicalPlan]，因此可以对 LogicalPlan 进行转换</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">lazy</span> <span class="keyword">val</span> analyzed: <span class="type">LogicalPlan</span> = &#123;</span><br><span class="line"></span><br><span class="line"> <span class="type">SparkSession</span>.setActiveSession(sparkSession)</span><br><span class="line"></span><br><span class="line"> sparkSession.sessionState.analyzer.executeAndCheck(logical)</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>通过 Catalog 确定每张表对应的字段集、字段类型、数据存储位置，生成Resolved Logical Plan</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">checkAnalysis</span></span>(plan: <span class="type">LogicalPlan</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">case</span> u: <span class="type">UnresolvedRelation</span> =&gt;</span><br><span class="line"></span><br><span class="line">  u.failAnalysis(<span class="string">s&quot;Table or view not found: <span class="subst">$&#123;u.tableIdentifier&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>ResolveRelations</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 关联表</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">lookupTableFromCatalog</span></span>(</span><br><span class="line"></span><br><span class="line">  u: <span class="type">UnresolvedRelation</span>,</span><br><span class="line"></span><br><span class="line">  defaultDatabase: <span class="type">Option</span>[<span class="type">String</span>] = <span class="type">None</span>): <span class="type">LogicalPlan</span> =&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Optimizer"><a href="#Optimizer" class="headerlink" title="Optimizer"></a>Optimizer</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">lazy</span> <span class="keyword">val</span> optimizedPlan: <span class="type">LogicalPlan</span> = sparkSession.sessionState.optimizer.execute(withCachedData)</span><br></pre></td></tr></table></figure>

<p>逻辑优化器，会进行谓词下推，列值裁剪，常量折叠，谓词合并等等一系列逻辑优化</p>
<p>根据预先定义好的规则对 Resolved Logical Plan 进行优化并生成 Optimized Logical Plan</p>
<h2 id="SparkPlanner"><a href="#SparkPlanner" class="headerlink" title="SparkPlanner"></a>SparkPlanner</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">lazy</span> <span class="keyword">val</span> sparkPlan: <span class="type">SparkPlan</span> = &#123;</span><br><span class="line"></span><br><span class="line"> <span class="type">SparkSession</span>.setActiveSession(sparkSession)</span><br><span class="line"></span><br><span class="line"> <span class="comment">// <span class="doctag">TODO:</span> We use next(), i.e. take the first plan returned by the planner, here for now,</span></span><br><span class="line"></span><br><span class="line"> <span class="comment">//    but we will implement to choose the best plan.</span></span><br><span class="line"></span><br><span class="line"> planner.plan(<span class="type">ReturnAnswer</span>(optimizedPlan)).next()</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>把 Logical Plan 转变为 Physical Plan</p>
<h2 id="执行-Physical-Plan"><a href="#执行-Physical-Plan" class="headerlink" title="执行 Physical Plan"></a>执行 Physical Plan</h2><p>lazy val executedPlan: SparkPlan = prepareForExecution(sparkPlan)</p>
<p><strong>转成RDD</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** Internal version of the RDD. Avoids copies and has no schema */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">lazy</span> <span class="keyword">val</span> toRdd: <span class="type">RDD</span>[<span class="type">InternalRow</span>] = &#123;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">if</span> (sparkSession.sessionState.conf.getConf(<span class="type">SQLConf</span>.<span class="type">USE_CONF_ON_RDD_OPERATION</span>)) &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">new</span> <span class="type">SQLExecutionRDD</span>(executedPlan.execute(), sparkSession.sessionState.conf)</span><br><span class="line"></span><br><span class="line"> &#125; <span class="keyword">else</span> &#123;</span><br><span class="line"></span><br><span class="line">  executedPlan.execute()</span><br><span class="line"></span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://sevncz.xyz/2020/12/07/Spark%20SQL%E8%BF%90%E8%A1%8C%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/IMG_1169.JPG">
      <meta itemprop="name" content="sevncz">
      <meta itemprop="description" content="努力赚钱">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sevncz's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/12/07/Spark%20SQL%E8%BF%90%E8%A1%8C%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/" class="post-title-link" itemprop="url">Spark SQL运行的基本原理</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-12-07 12:22:00" itemprop="dateCreated datePublished" datetime="2020-12-07T12:22:00+08:00">2020-12-07</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2020-12-11 22:25:09" itemprop="dateModified" datetime="2020-12-11T22:25:09+08:00">2020-12-11</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Spark SQL 是 Spark 中的一个子模块，主要用于操作结构化数据。它具有以下特点：</p>
<ul>
<li>能够将 SQL 查询与 Spark 程序无缝混合，允许您使用 SQL 或 DataFrame API 对结构化数据进行查询；</li>
<li>支持多种开发语言；</li>
<li>支持多达上百种的外部数据源，包括 Hive，Avro，Parquet，ORC，JSON 和 JDBC 等；</li>
<li>支持 HiveQL 语法以及 Hive SerDes 和 UDF，允许你访问现有的 Hive 仓库；</li>
<li>支持标准的 JDBC 和 ODBC 连接；</li>
<li>支持优化器，列式存储和代码生成等特性；</li>
<li>支持扩展并能保证容错。</li>
</ul>
<h2 id="DataFrame和RDD"><a href="#DataFrame和RDD" class="headerlink" title="DataFrame和RDD"></a>DataFrame和RDD</h2><p>主要区别在于RDD面向的是非结构化数据，DataFreame面向的是结构化数据。</p>
<p>DataFrame 内部的有明确 Scheme 结构，即列名、列字段类型都是已知的，这带来的好处是可以减少数据读取以及更好地优化执行计划，从而保证查询效率。</p>
<h2 id="DataFrame-和-RDDs-应该如何选择？"><a href="#DataFrame-和-RDDs-应该如何选择？" class="headerlink" title="DataFrame 和 RDDs 应该如何选择？"></a>DataFrame 和 RDDs 应该如何选择？</h2><ul>
<li>如果你想使用函数式编程而不是 DataFrame API，则使用 RDDs；</li>
<li>如果你的数据是非结构化的 (比如流媒体或者字符流)，则使用 RDDs，</li>
<li>如果你的数据是结构化的 (如 RDBMS 中的数据) 或者半结构化的 (如日志)，出于性能上的考虑，应优先使用 DataFrame。</li>
</ul>
<h2 id="DataSet"><a href="#DataSet" class="headerlink" title="DataSet"></a>DataSet</h2><p>DataSet 也是分布式的数据集合，在Spark1.6版本引入，它继承了RDD和DataFrame的优点，具备强类型的特点，同时支持Lambda函数，但只能在 Scala 和 Java 语言中使用。在 Spark 2.0 后，为了方便开发者，Spark 将 DataFrame 和 Dataset 的 API 融合到一起，提供了结构化的 API(Structured API)，即用户可以通过一套标准的 API 就能完成对两者的操作。</p>
<p>静态类型与运行时类型安全</p>
<p>静态类型 (Static-typing) 与运行时类型安全 (runtime type-safety) 主要表现如下:</p>
<p>在实际使用中，如果你用的是 Spark SQL 的查询语句，则直到运行时你才会发现有语法错误，而如果你用的是 DataFrame 和 Dataset，则在编译时就可以发现错误 (这节省了开发时间和整体代价)。DataFrame 和 Dataset 主要区别在于：</p>
<p>在 DataFrame 中，当你调用了 API 之外的函数，编译器就会报错，但如果你使用了一个不存在的字段名字，编译器依然无法发现。而 Dataset 的 API 都是用 Lambda 函数和 JVM 类型对象表示的，所有不匹配的类型参数在编译时就会被发现。</p>
<p>以上这些最终都被解释成关于类型安全图谱，对应开发中的语法和分析错误。在图谱中，Dataset 最严格，但对于开发者来说效率最高。</p>
<h2 id="Untypeed-和-Typed"><a href="#Untypeed-和-Typed" class="headerlink" title="Untypeed 和 Typed"></a>Untypeed 和 Typed</h2><p>DataFrame API 被标记为 Untyped API，而 DataSet API 被标记为 Typed API。DataFrame 的 Untyped 是相对于语言或 API 层面而言，它确实有明确的 Scheme 结构，即列名，列类型都是确定的，但这些信息完全由 Spark 来维护，Spark 只会在运行时检查这些类型和指定类型是否一致。这也就是为什么在 Spark 2.0 之后，官方推荐把 DataFrame 看做是 DatSet[Row]，Row 是 Spark 中定义的一个 trait，其子类中封装了列字段的信息。</p>
<p>相对而言，DataSet 是 Typed 的，即强类型。如下面代码，DataSet 的类型由 Case Class(Scala) 或者 Java Bean(Java) 来明确指定的，在这里即每一行数据代表一个 Person，这些信息由 JVM 来保证正确性，所以字段名错误和类型错误在编译的时候就会被 IDE 所发现。</p>
<p>val dataSet: Dataset[Person] = spark.read.json(“people.json”).as[Person]</p>
<h2 id="DataFrame-amp-DataSet-amp-RDDs-总结"><a href="#DataFrame-amp-DataSet-amp-RDDs-总结" class="headerlink" title="DataFrame &amp; DataSet &amp; RDDs 总结"></a>DataFrame &amp; DataSet &amp; RDDs 总结</h2><ul>
<li>RDDs 适合非结构化数据的处理，而 DataFrame &amp; DataSet 更适合结构化数据和半结构化的处理；</li>
<li>DataFrame &amp; DataSet 可以通过统一的 Structured API 进行访问，而 RDDs 则更适合函数式编程的场景；</li>
<li>相比于 DataFrame 而言，DataSet 是强类型的 (Typed)，有着更为严格的静态类型检查；</li>
<li>DataSets、DataFrames、SQL 的底层都依赖了 RDDs API，并对外提供结构化的访问接口。</li>
</ul>
<h2 id="运行原理"><a href="#运行原理" class="headerlink" title="运行原理"></a>运行原理</h2><p>DataFrame、DataSet 和 Spark SQL 的实际执行流程都是相同的：</p>
<ol>
<li>进行 DataFrame/Dataset/SQL 编程；</li>
<li>如果是有效的代码，即代码没有编译错误，Spark 会将其转换为一个逻辑计划；</li>
<li>Spark 将此逻辑计划转换为物理计划，同时进行代码优化；</li>
<li>Spark 然后在集群上执行这个物理计划 (基于 RDD 操作) 。</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://sevncz.xyz/2020/12/05/Spark%E8%BF%90%E8%A1%8C%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/IMG_1169.JPG">
      <meta itemprop="name" content="sevncz">
      <meta itemprop="description" content="努力赚钱">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sevncz's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/12/05/Spark%E8%BF%90%E8%A1%8C%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/" class="post-title-link" itemprop="url">Spark 运行的基本原理</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-12-05 12:22:00" itemprop="dateCreated datePublished" datetime="2020-12-05T12:22:00+08:00">2020-12-05</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2020-12-11 22:24:58" itemprop="dateModified" datetime="2020-12-11T22:24:58+08:00">2020-12-11</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="RDD基本概念"><a href="#RDD基本概念" class="headerlink" title="RDD基本概念"></a><strong>RDD</strong>基本概念</h2><p>A Resilient Distributed Dataset (RDD), the basic abstraction in Spark. Represents an immutable, partitioned collection of elements that can be operated on in parallel.</p>
<ul>
<li><p>RDD是Resilient Distributed Dataset(弹性分布式数据集)的简称。RDD的弹性体现在计算方面，当Spark进行计算时，某一阶段出现数据丢失或者故障，可以通过RDD的血缘关系就行修复。     </p>
</li>
<li><ul>
<li>\1. 内存的弹性：内存与磁盘的自动切换    </li>
<li>\2. 容错的弹性：数据丢失可以自动恢复</li>
<li>\3. 计算的弹性：计算出错重试机制</li>
<li>\4. 分片的弹性：根据需要重新分片 </li>
</ul>
</li>
<li><p>RDD是不可变(immutable)的，一旦创建就不可改变。RDDA–&gt;RDDB，RDDA 经过转换操作变成RDDB，这两个RDD具有血缘关系，但是是两个不同的RDD，体现了RDD一旦创建就不可变的性质。</p>
</li>
</ul>
<h2 id="RDD特点"><a href="#RDD特点" class="headerlink" title="RDD特点"></a>RDD特点</h2><ul>
<li>A list of partitions</li>
<li>A function for computing each split</li>
<li>A list of dependencies on other RDDs</li>
<li>Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD is hash-partitioned)</li>
<li>Optionally, a list of preferred locations to compute each split on (e.g. block locations for an HDFS file)</li>
</ul>
<p>源码解析</p>
<ul>
<li>A list of partitions</li>
</ul>
<p>/**</p>
<p> * Implemented by subclasses to return the set of partitions in this RDD. This method will only</p>
<p> * be called once, so it is safe to implement a time-consuming computation in it.</p>
<p> *</p>
<p> * The partitions in this array must satisfy the following property:</p>
<p> *  <code>rdd.partitions.zipWithIndex.forall &#123; case (partition, index) =&gt; partition.index == index &#125;</code></p>
<p> */</p>
<p>protected def getPartitions: Array[Partition]</p>
<ul>
<li>compute函数的入参必然是partition，因为对RDD做计算相当于对每个partition做计算</li>
</ul>
<p>/**</p>
<p> * :: DeveloperApi ::</p>
<p> * Implemented by subclasses to compute a given partition.</p>
<p> */</p>
<p>@DeveloperApi</p>
<p>def compute(split: Partition, context: TaskContext): Iterator[T]</p>
<ul>
<li>RDD之间有依赖关系</li>
</ul>
<p>/**</p>
<p> * Implemented by subclasses to return how this RDD depends on parent RDDs. This method will only</p>
<p> * be called once, so it is safe to implement a time-consuming computation in it.</p>
<p> */</p>
<p>protected def getDependencies: Seq[Dependency[_]] = deps</p>
<ul>
<li>Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD is hash-partitioned)</li>
</ul>
<p>/**</p>
<p> * Optionally overridden by subclasses to specify placement preferences.</p>
<p> */</p>
<p>protected def getPreferredLocations(split: Partition): Seq[String] = Nil</p>
<ul>
<li>Optionally, a list of preferred locations to compute each split on (e.g. block locations for an HDFS file)</li>
</ul>
<p>/** Optionally overridden by subclasses to specify how they are partitioned. */</p>
<p>@transient val partitioner: Option[Partitioner] = None</p>
<h2 id="RDD操作"><a href="#RDD操作" class="headerlink" title="RDD操作"></a>RDD操作</h2><ul>
<li><p>Transformations：接受RDD并返回RDD</p>
</li>
<li><ul>
<li>Transformation采用惰性调用机制，每个RDD记录父RDD转换的方法，这种调用链表称之为血缘（lineage）</li>
</ul>
</li>
<li><p>Actions：接受RDD但是返回非RDD</p>
</li>
<li><ul>
<li>Action调用会直接计算</li>
</ul>
</li>
</ul>
<h2 id="DAG、Stage、Shuffle"><a href="#DAG、Stage、Shuffle" class="headerlink" title="DAG、Stage、Shuffle"></a>DAG、Stage、Shuffle</h2><p>有向无环图，DAGScheduler负责生成DAG，然后将程序分发到分布式计算集群，按计算阶段的先后关系调度执行</p>
<p>并不是RDD上的每一个转换函数都会生成一个计算计算，通过观察DAG图，RDD之间的转换连接线呈现多对多交叉连接的时候，就会产生新的阶段，一个RDD代表一个数据集，每一个RDD都包含多个分片。</p>
<p>一个数据集中的多个数据分片需要进行分区传输，写入到另一个数据集的不同分片中，这种数据分区交叉传输的操作，和MapReduce类似，是shuffle过程，Spark也需要通过shuffle将数据进行重新组合，相同的Key的数据放在一起，进行聚合、关联等操作，因而每次shuffle都产生新的计算阶段。这也是为什么计算阶段会有依赖关系，它需要的数据来源于前面一个或多个计算阶段产生的数据，必须等待前面的阶段执行完毕才能进行shuffle，并得到数据</p>
<p>所以，计算阶段的划分以及是shuffle，而不是转换函数的类型，有的函数有时候有shuffle，有时候没有。</p>
<p>RDD 已经进行过分区，分区数目和分区Key不变，就不需要再进行shuffle，这种不需要进行shuffle的依赖，被称作窄依赖；相反的，需要进行shuffle的依赖，被称作宽依赖。</p>
<p>为什么<strong>Spark</strong>比<strong>MapReduce</strong>的效率更高？</p>
<p>从本质上看，Spark也算是一种MapReduce计算模型的不同实现。Hadoop MapReduce简单粗暴的根据shuffle将大数据计算分成了Map和Reduce阶段，然后就算完事了。而Spark更细腻一些，将前一个的Reduce和后一个的Map连接起来，当作一个阶段持续计算，形成一个更加优雅、高效的计算模型，虽然本质上仍然是Map和Reduce，但是这种多个计算阶段依赖执行的方案可以有效减少对HDFS的访问，减少作业的调度执行次数，因此执行速度也更快。并且Hadoop MapReduce主要使用磁盘存储Shuffle过程中的数据，Spark优先使用内存进行数据存储，包括RDD数据，除非是内存不够用了，否则是尽可能使用内存，这也是Spark性能比Hadoop MapReduce高的原因。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://sevncz.xyz/2020/12/04/Hive%E8%BF%90%E8%A1%8C%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/IMG_1169.JPG">
      <meta itemprop="name" content="sevncz">
      <meta itemprop="description" content="努力赚钱">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sevncz's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/12/04/Hive%E8%BF%90%E8%A1%8C%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/" class="post-title-link" itemprop="url">Hive运行的基本原理</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-12-04 12:22:00" itemprop="dateCreated datePublished" datetime="2020-12-04T12:22:00+08:00">2020-12-04</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2020-12-11 22:24:39" itemprop="dateModified" datetime="2020-12-11T22:24:39+08:00">2020-12-11</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Hive 是一个构建在 Hadoop 之上的数据仓库，它可以将结构化的数据文件映射成表，并提供类 SQL 查询功能，用于查询的 SQL 语句会被转化为 MapReduce 作业，然后提交到 Hadoop 上运行。</p>
<p>特点：</p>
<ol>
<li>简单、容易上手 (提供了类似 sql 的查询语言 hql)，使得精通 sql 但是不了解 Java 编程的人也能很好地进行大数据分析；</li>
<li>灵活性高，可以自定义用户函数 (UDF) 和存储格式；</li>
<li>为超大的数据集设计的计算和存储能力，集群扩展容易;</li>
<li>统一的元数据管理，可与 presto／impala／sparksql 等共享数据；</li>
<li>执行延迟高，不适合做数据的实时处理，但适合做海量数据的离线处理。</li>
</ol>
<h2 id="基本数据类型"><a href="#基本数据类型" class="headerlink" title="基本数据类型"></a>基本数据类型</h2><table>
<thead>
<tr>
<th>大类</th>
<th>类型</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Integers</strong>（整型）</td>
<td>TINYINT—1 字节的有符号整数 SMALLINT—2 字节的有符号整数 INT—4 字节的有符号整数 BIGINT—8 字节的有符号整数</td>
</tr>
<tr>
<td><strong>Boolean</strong>（布尔型）</td>
<td>BOOLEAN—TRUE/FALSE</td>
</tr>
<tr>
<td><strong>Floating point numbers</strong>（浮点型）</td>
<td>FLOAT— 单精度浮点型 DOUBLE—双精度浮点型</td>
</tr>
<tr>
<td><strong>Fixed point numbers</strong>（定点数）</td>
<td>DECIMAL—用户自定义精度定点数，比如 DECIMAL(7,2)</td>
</tr>
<tr>
<td><strong>String types</strong>（字符串）</td>
<td>STRING—指定字符集的字符序列 VARCHAR—具有最大长度限制的字符序列 CHAR—固定长度的字符序列</td>
</tr>
<tr>
<td><strong>Date and time types</strong>（日期时间类型）</td>
<td>TIMESTAMP — 时间戳 TIMESTAMP WITH LOCAL TIME ZONE — 时间戳，纳秒精度 DATE—日期类型</td>
</tr>
<tr>
<td><strong>Binary types</strong>（二进制类型）</td>
<td>BINARY—字节序列</td>
</tr>
</tbody></table>
<h2 id="隐式转换"><a href="#隐式转换" class="headerlink" title="隐式转换"></a>隐式转换</h2><p>type - primitive type - number - double - float - biting - int - smallint - tinyint</p>
<p>​                  - boolean       - string</p>
<h2 id="复杂类型"><a href="#复杂类型" class="headerlink" title="复杂类型"></a>复杂类型</h2><table>
<thead>
<tr>
<th>类型</th>
<th>描述</th>
<th>示例</th>
</tr>
</thead>
<tbody><tr>
<td><strong>STRUCT</strong></td>
<td>类似于对象，是字段的集合，字段的类型可以不同，可以使用 名称.字段名 方式进行访问</td>
<td>STRUCT (‘xiaoming’, 12 , ‘2018-12-12’)</td>
</tr>
<tr>
<td><strong>MAP</strong></td>
<td>键值对的集合，可以使用 名称[key] 的方式访问对应的值</td>
<td>map(‘a’, 1, ‘b’, 2)</td>
</tr>
<tr>
<td><strong>ARRAY</strong></td>
<td>数组是一组具有相同类型和名称的变量的集合，可以使用 名称[index] 访问对应的值</td>
<td>ARRAY(‘a’, ‘b’, ‘c’, ‘d’)</td>
</tr>
</tbody></table>
<p>内容格式</p>
<p>Hive 默认使用了几个平时很少出现的字符，这些字符一般不会作为内容出现在文件中</p>
<p>\n：对于文本文件来说，每行是一条记录，所以可以使用换行符来分割记录</p>
<p>^A：分割字段 (列)，在 CREATE TABLE 语句中也可以使用八进制编码 \001 来表示</p>
<p>^B：用于分割 ARRAY 或者 STRUCT 中的元素，或者用于 MAP 中键值对之间的分割，在 CREATE TABLE 语句中也可以使用八进制编码 \002 表示</p>
<p>^C：用于 MAP 中键和值之间的分割，在 CREATE TABLE 语句中也可以使用八进制编码 \003 表示</p>
<h2 id="存储格式"><a href="#存储格式" class="headerlink" title="存储格式"></a>存储格式</h2><p><strong>TextFile**</strong>：**存储为纯文本文件。这是Hive默认的文件存储格式。这种存储方式数据不做压缩，磁盘开销大，数据解析开销大。</p>
<p><strong>SequenceFile**</strong>：**SequenceFile 是 Hadoop API 提供的一种二进制文件，它将数据以&lt;key,value&gt;的形式序列化到文件中。这种二进制文件内部使用 Hadoop 的标准的 Writable 接口实现序列化和反序列化。它与 Hadoop API 中的 MapFile 是互相兼容的。Hive 中的 SequenceFile 继承自 Hadoop API 的 SequenceFile，不过它的 key 为空，使用 value 存放实际的值，这样是为了避免 MR 在运行 map 阶段进行额外的排序操作。</p>
<p><strong>RCFile**</strong>：**RCFile 文件格式是 FaceBook 开源的一种 Hive 的文件存储格式，首先将表分为几个行组，对每个行组内的数据按列存储，每一列的数据都是分开存储。</p>
<p><strong>ORC Files：</strong>ORC 是在一定程度上扩展了 RCFile，是对 RCFile 的优化。</p>
<p><strong>Avro Files**</strong>：**Avro 是一个数据序列化系统，设计用于支持大批量数据交换的应用。它的主要特点有：支持二进制序列化方式，可以便捷，快速的处理大量数据；动态语言友好，Avro提供的机制使动态语言可以方便的处理Avro数据</p>
<p><strong>Parquet**</strong>：**Parquet 是基于 Dremel 的数据模型和算法实现的，面向分析型业务的列式存储格式。它通过按列进行高效压缩和特殊的编码技术，从而在降低存储空间的同时提高了IO效率。</p>
<p><strong>以上压缩格式中</strong> <strong>ORC</strong> <strong>和</strong> <strong>Parquet</strong> <strong>的综合性能突出，使用较为广泛，推荐使用这两种格式。</strong></p>
<p>通常在创建表的时候使用 STORED AS 参数指定存储格式</p>
<p>各个存储文件类型指定方式如下：</p>
<ul>
<li>STORED AS TEXTFILE</li>
<li>STORED AS SEQUENCEFILE</li>
<li>STORED AS ORC</li>
<li>STORED AS PARQUET</li>
<li>STORED AS AVRO</li>
<li>STORED AS RCFILE</li>
</ul>
<h2 id="内部表和外部表"><a href="#内部表和外部表" class="headerlink" title="内部表和外部表"></a>内部表和外部表</h2><p>内部表又叫做管理表，创建表时不做任何指定，默认创建的就是内部表。创建外部表需要使用 External 进行修饰</p>
<ul>
<li><strong>存储位置</strong></li>
</ul>
<p>​    内部表：由hive.metastore.warehouse.dir指定，默认在hdfs的/user/hive/warehouse/数据库名.db/表名/ 目录下</p>
<p>​    外部表：创建表时由 Location 参数指定</p>
<ul>
<li><strong>导入数据</strong></li>
</ul>
<p>​    内部表：将数据移动到子弟的数据仓库目录下，数据的生命周期由 Hive 来进行管理</p>
<p>​    外部表：不回移动数据到数据仓库目录，只是在原数据中存储数据的位置</p>
<ul>
<li><strong>删除表</strong></li>
</ul>
<p>​    内部表：删除元数据（metadata）和文件</p>
<p>​    外部表：只删除元数据（metadata）</p>
<h2 id="SQL转化为MapReduce的过程"><a href="#SQL转化为MapReduce的过程" class="headerlink" title="SQL转化为MapReduce的过程"></a>SQL转化为MapReduce的过程</h2><ol>
<li>语法解析：Antlr 定义 SQL 的语法规则，完成 SQL 词法，语法解析，将 SQL 转化为抽象 语法树 AST Tree；</li>
<li>语义解析：遍历 AST Tree，抽象出查询的基本组成单元 QueryBlock；</li>
<li>生成逻辑执行计划：遍历 QueryBlock，翻译为执行操作树 OperatorTree；</li>
<li>优化逻辑执行计划：逻辑层优化器进行 OperatorTree 变换，合并不必要的 ReduceSinkOperator，减少 shuffle 数据量；</li>
<li>生成物理执行计划：遍历 OperatorTree，翻译为 MapReduce 任务；</li>
<li>优化物理执行计划：物理层优化器进行 MapReduce 任务的变换，生成最终的执行计划。</li>
</ol>
<p>源码分析</p>
<p><strong>Hive</strong>是执行命令的流程</p>
<ol>
<li><p>启动时初始化SessionState，初始化Config，初始化Log</p>
</li>
<li><p>CliDriver main中接受命令行</p>
</li>
<li><p>处理命令行，分为以下几种情况</p>
</li>
<li><ol>
<li>处理quit和exit，直接退出</li>
<li>处理source，执行SQL文件</li>
<li>处理感叹号命令</li>
<li>其他命令，包括select等SQL，CommandProcessorFactory.get(tokens, (HiveConf) conf); 在该工厂中会通过用户输入的第一个单词判断命令类型，在HiveCommand这个枚举中定义了一些非SQL查询操作，匹配到命令会选择合适的CommandProcessor实现，比如dfs命令对应DFSProcessor，set命令对应的SetPRocessor等，如果是Select之类的SQL查询，则返回null，然后为这些SQL命令创建一个Driver。</li>
</ol>
</li>
<li><p>获得processor之后开始执行，int processLocalCmd(String cmd, CommandProcessor proc, CliSessionState ss)，调用processor的run方法开始执行命令</p>
</li>
<li><p>执行完成之后，通过List<FieldSchema> fieldSchemas = qp.getSchema().getFieldSchemas()获取结果的列名，并随后打印，最后再打印结果集</p>
</li>
</ol>
<h2 id="Hive执行SQL语句"><a href="#Hive执行SQL语句" class="headerlink" title="Hive执行SQL语句"></a>Hive执行SQL语句</h2><p>根据上一节内容，在获取processor之后开始执行命令，这里我们来到了Driver，我们进入到 private CommandProcessorResponse runInternal(String command, boolean alreadyCompiled) 这样一个方法，在该方法中发现一个有意思的东西，Hook，意味着可以写一个外部class配置到hive中查看hive的执行情况，接着进入重点</p>
<ol>
<li><p>ret = compileInternal(command); 在该方法中主要是将SQL解析为物理和逻辑执行计划，和Spark差不多</p>
</li>
<li><ol>
<li>将SQL解析为AST树：ASTNode tree = pd.parse(command, ctx); </li>
<li>初始化事务管理器，记录这次query的信息：SessionState.get().initTxnMgr(conf);</li>
<li>执行hook：tree = hook.preAnalyze(hookCtx, tree);  </li>
<li>创建逻辑和物理执行计划：sem.analyze(tree, ctx);</li>
<li>执行hook：hook.postAnalyze(hookCtx, sem.getRootTasks()); </li>
</ol>
</li>
<li><p>ret = execute();</p>
</li>
<li><ol>
<li>循环执行hook</li>
<li>初始化运行容器：DriverContext driverCxt = new DriverContext(ctx); driverCxt.prepare(plan); </li>
<li> 添加running任务：driverCxt.addToRunnable(tsk); 任务会进入一个队列 Queue&lt;Task&lt;? extends Serializable&gt;&gt; runnable; runnable.add(tsk); </li>
<li>在一个while中启动任务：TaskRunner runner = launchTask(task, queryId, noName, jobname, jobs, driverCxt);</li>
<li>poll已经完成的任务，并加到hookContext的完成任务列表中：TaskRunner tskRun = driverCxt.pollFinished(); hookContext.addCompleteTask(tskRun);</li>
<li>遍历子任务加到running：for (Task&lt;? extends Serializable&gt; child : tsk.getChildTasks()) … driverCxt.addToRunnable(child);</li>
<li>最后计算CPU使用情况，任务完成：plan.setDone()，将该planId加到一个Set集合中</li>
</ol>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>


<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">sevncz@xyz</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  







  






</body>
</html>
