<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto+Slab:300,300italic,400,400italic,700,700italic|PT+Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.1/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"sevncz.xyz","root":"/","images":"/images","scheme":"Pisces","version":"8.1.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}};
  </script>
<meta name="description" content="努力赚钱">
<meta property="og:type" content="website">
<meta property="og:title" content="Sevncz&#39;s Blog">
<meta property="og:url" content="http://sevncz.xyz/page/2/index.html">
<meta property="og:site_name" content="Sevncz&#39;s Blog">
<meta property="og:description" content="努力赚钱">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="sevncz">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://sevncz.xyz/page/2/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>
<title>Sevncz's Blog</title>
  



  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Sevncz's Blog</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <section class="post-toc-wrap sidebar-panel">
        </section>
        <!--/noindex-->

        <section class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="sevncz"
      src="/images/IMG_1169.JPG">
  <p class="site-author-name" itemprop="name">sevncz</p>
  <div class="site-description" itemprop="description">努力赚钱</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">18</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/Sevncz" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Sevncz" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



        </section>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://sevncz.xyz/2020/12/16/Redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/IMG_1169.JPG">
      <meta itemprop="name" content="sevncz">
      <meta itemprop="description" content="努力赚钱">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sevncz's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/12/16/Redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6/" class="post-title-link" itemprop="url">Redis持久化机制</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-12-16 10:16:48" itemprop="dateCreated datePublished" datetime="2020-12-16T10:16:48+08:00">2020-12-16</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2020-12-22 22:39:55" itemprop="dateModified" datetime="2020-12-22T22:39:55+08:00">2020-12-22</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Redis/" itemprop="url" rel="index"><span itemprop="name">Redis</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>Redis 的数据存在内存中，这样响应速度会非常快，但是不能忽视的问题是，一旦 Redis 宕机，数据就会丢失，如果从后端数据库恢复这些数据，会存在两个问题：</p>
<ol>
<li>需要频繁访问数据库，会给数据库带来巨大的压力；</li>
<li>这些数据是从慢速数据库中读取出来的，性能肯定比不上从 Redis 中读取，导致使用这些数据的应用程序响应变慢；</li>
</ol>
<p>所以，Redis 提供了两个持久化机制，AOF（Append Only File）日志 和 RDB（Redis DataBase）快照。</p>
<h2 id="AOF日志实现"><a href="#AOF日志实现" class="headerlink" title="AOF日志实现"></a>AOF日志实现</h2><p>一般数据库的日志是写前日志（WFL，Write Ahead Log），也就是在数据写入前，先把修改的数据记录到日志文件中，以便发生故障时恢复。不过，AOF 日志正好相反，它是写后日志，“写后”的意思是 Redis 是先执行命令，把数据写入内存，然后才记录日志。</p>
<h3 id="AOF日志内容"><a href="#AOF日志内容" class="headerlink" title="AOF日志内容"></a>AOF日志内容</h3><p>传统数据库的日志，例如 redo log（重做日志），记录的是修改后的数据，而 AOF 里记录的是 Redis 收到的每一条命令，这些命令是以文本形式保存的。</p>
<h3 id="AOF写入优化机制"><a href="#AOF写入优化机制" class="headerlink" title="AOF写入优化机制"></a>AOF写入优化机制</h3><p>为了避免额外的检查开销，Redis 在向 AOF 写入日志的时候，不会先去对命令进行语法检查，所以，如果先记录日志再执行命令的话，可能在日志文件中记录了错误的命令，Redis 在恢复数据的时候，就可能会出错。</p>
<p>而后写日志机制，就是先让系统执行命令，成功之后再记录日志，这样就可以避免出现记录错误命令的情况。</p>
<p>此外，AOF 后写机制还有一个好处：它是在命令执行后才记录日志，所以不会阻塞当前的写操作。</p>
<p>当然 AOF 也有两个潜在的风险：</p>
<ol>
<li>数据丢失，在还未来得及写入日志就发生宕机时；</li>
<li>阻塞其他操作，虽然避免了对当前操作的阻塞，但可能对下一个操作带来阻塞风险，这是因为 AOF 日志也是在主线程中执行的，如果在写把日志写入磁盘时，系统磁盘写压力大，就会导致写盘很慢，进而导致后续的操作也无法执行；</li>
</ol>
<h3 id="三种写磁盘的方式"><a href="#三种写磁盘的方式" class="headerlink" title="三种写磁盘的方式"></a>三种写磁盘的方式</h3><p>AOF 提供了三种写回磁盘的选择，也就是 AOF 配置项 appendfsync 的三个可选值。</p>
<ul>
<li>Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；</li>
<li>Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；</li>
<li>No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。</li>
</ul>
<p>针对避免主线程阻塞和减少数据丢失问题，这三种写回策略都无法做到两全其美。</p>
<ul>
<li>“同步写回”可以做到基本不丢数据，但是它在每一个写命令后都有一个慢速的落盘操作，不可避免地会影响主线程性能；</li>
<li>虽然“操作系统控制的写回”在写完缓冲区后，就可以继续执行后续的命令，但是落盘的时机已经不在 Redis 手中了，只要 AOF 记录没有写回磁盘，一旦宕机对应的数据就丢失了；</li>
<li>“每秒写回”采用一秒写回一次的频率，避免了“同步写回”的性能开销，虽然减少了对系统性能的影响，但是如果发生宕机，上一秒内未落盘的命令操作仍然会丢失。所以，这只能算是，在避免影响主线程性能和避免数据丢失两者间取了个折中。</li>
</ul>
<p>三种写回时机的优缺点如下：</p>
<img src="/2020/12/16/Redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6/AOF%E5%86%99%E5%9B%9E%E6%9C%BA%E5%88%B6%E4%BC%98%E7%BC%BA%E7%82%B9.jpg" class="">

<p>到这里，我们就可以根据系统对高性能和高可靠性的要求，来选择使用哪种写回策略了。总结一下就是：想要获得高性能，就选择 No 策略；如果想要得到高可靠性保证，就选择 Always 策略；如果允许数据有一点丢失，又希望性能别受太大影响的话，那么就选择 Everysec 策略。</p>
<h3 id="AOF-的性能问题"><a href="#AOF-的性能问题" class="headerlink" title="AOF 的性能问题"></a>AOF 的性能问题</h3><p>AOF 是以文件的形式在记录接收到的所有写命令。随着接收的写命令越来越多，AOF 文件会越来越大。</p>
<p>AOF 文件过大会会导致性能问题，主要在于以下3个方面：</p>
<ol>
<li><p>操作系统对文件大小有限制，不能无限增大。 </p>
</li>
<li><p>过大的文件，追加记录效率低。 </p>
</li>
<li><p>Redis异常关闭重启之后，AOF 记录的命令要一个一个被重新执行，文件过大导致执行时间长，影响Redis可用性。</p>
</li>
</ol>
<h3 id="AOF-重写机制"><a href="#AOF-重写机制" class="headerlink" title="AOF 重写机制"></a>AOF 重写机制</h3><p>为解决 AOF 文件过大导致的性能为题，Redis 提供了 AOF 重写机制。</p>
<p>AOF重写机制指的是，对过大的AOF文件进行重写，以此来压缩AOF文件的大小。</p>
<p>具体的实现是：检查当前键值数据库中的键值对，记录键值对的最终状态，从而实现对 某个键值对 重复操作后产生的多条操作记录压缩成一条 的效果。进而实现压缩AOF文件的大小。</p>
<p>AOF 重写过程是由后台子进程 <strong>bgrewriteaof</strong> 来完成的，这也是为了避免阻塞主线程，导致数据库性能下降。</p>
<p>AOF 重写日志的过程总结为两部分：</p>
<ol>
<li>一次拷贝</li>
<li>两处日志</li>
</ol>
<p>“一个拷贝”就是指，每次执行重写时，主线程 fork 出后台的 bgrewriteaof 子进程。此时，fork 会把主线程的内存拷贝一份给 bgrewriteaof 子进程，这里面就包含了数据库的最新数据。然后，bgrewriteaof 子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志。</p>
<p>“两处日志”又是什么呢？因为主线程未阻塞，仍然可以处理新来的操作。此时，如果有写操作，第一处日志就是指正在使用的 AOF 日志，Redis 会把这个操作写到它的缓冲区。这样一来，即使宕机了，这个 AOF 日志的操作仍然是齐全的，可以用于恢复。而第二处日志，就是指新的 AOF 重写日志。这个操作也会被写到重写日志的缓冲区。这样，重写日志也不会丢失最新的操作。等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件，以保证数据库最新状态的记录。此时，我们就可以用新的 AOF 文件替代旧文件了。</p>
<img src="/2020/12/16/Redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6/AOF%E9%9D%9E%E9%98%BB%E5%A1%9E%E7%9A%84%E9%87%8D%E5%86%99%E8%BF%87%E7%A8%8B.jpg" class="">

<p>总结来说，每次 AOF 重写时，Redis 会先执行一个内存拷贝，用于重写；然后，使用两个日志保证在重写过程中，新写入的数据不会丢失。而且，因为 Redis 采用额外的线程进行数据重写，所以，这个过程并不会阻塞主线程。</p>
<h2 id="RDB-文件实现"><a href="#RDB-文件实现" class="headerlink" title="RDB 文件实现"></a>RDB 文件实现</h2><p>AOF 的好处：只需要记录日志，坏处：宕机之后恢复慢。</p>
<p>RDB把某一时刻的状态以文件的形式写到磁盘上，即使宕机，RDB也不会丢失。</p>
<p>和 AOF 相比，RDB 记录的是某一时刻的数据，并不是操作，所以，在做数据恢复时，我们可以直接把 RDB 文件读入内存，很快地完成恢复。</p>
<h3 id="如何避免快照时阻塞"><a href="#如何避免快照时阻塞" class="headerlink" title="如何避免快照时阻塞"></a>如何避免快照时阻塞</h3><p>Redis 提供了两个命令来生成RDB文件，分别是save和bgsave。</p>
<ul>
<li><p>save：在主线程中执行，会导致阻塞；</p>
</li>
<li><p>bgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是 Redis RDB 文件生成的默认配置。</p>
</li>
</ul>
<p>bgsave 可以避免阻塞，但避免阻塞和正常处理写操作并不是一回事。此时，主线程的确没有阻塞，可以正常接收请求，但是，为了保证快照完整性，它只能处理读操作，因为不能修改正在执行快照的数据。</p>
<p>为了快照而暂停写操作，肯定是不能接受的。所以这个时候，Redis 就会借助操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作。</p>
<p>简单来说，bgsave 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据。bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件。</p>
<p>此时，如果主线程对这些数据也都是读操作（例如图中的键值对 A），那么，主线程和 bgsave 子进程相互不影响。但是，如果主线程要修改一块数据（例如图中的键值对 C），那么，这块数据就会被复制一份，生成该数据的副本。然后，bgsave 子进程会把这个副本数据写入 RDB 文件，而在这个过程中，主线程仍然可以直接修改原来的数据。</p>
<img src="/2020/12/16/Redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6/%E5%86%99%E6%97%B6%E5%A4%8D%E5%88%B6%E6%9C%BA%E5%88%B6%E4%BF%9D%E8%AF%81%E5%BF%AB%E7%85%A7%E6%9C%9F%E9%97%B4%E6%95%B0%E6%8D%AE%E5%8F%AF%E4%BF%AE%E6%94%B9.jpg" class="">

<p>这既保证了快照的完整性，也允许主线程同时对数据进行修改，避免了对正常业务的影响。</p>
<h3 id="RDB的执行频率"><a href="#RDB的执行频率" class="headerlink" title="RDB的执行频率"></a>RDB的执行频率</h3><p>虽然 bgsave 执行时不阻塞主线程，但是，如果频繁地执行全量快照，也会带来两方面的开销。</p>
<ol>
<li><p>会给磁盘造成很大的压力 </p>
</li>
<li><p>fork子进程会阻塞主线程，主线程的内存越大，fork子线程时，阻塞的时间就会越长（fork操作执行时，内核需要给子进程拷贝主线程的页表。如果主线程的内存大，页表也相应大，拷贝页表耗时长，会阻塞主线程。）</p>
</li>
</ol>
<p>此时，我们可以做增量快照，所谓增量快照，就是指，做了一次全量快照后，后续的快照只对修改的数据进行快照记录，这样可以避免每次全量快照的开销。</p>
<p>虽然跟 AOF 相比，快照的恢复速度快，但是，快照的频率不好把握，如果频率太低，两次快照间一旦宕机，就可能有比较多的数据丢失。如果频率太高，又会产生额外开销，那么，还有什么方法既能利用 RDB 的快速恢复，又能以较小的开销做到尽量少丢数据呢？</p>
<p>Redis 4.0 中提出了一个混合使用 AOF 日志和内存快照的方法。简单来说，内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。</p>
<p>这样一来，快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，AOF 日志也只用记录两次快照间的操作，也就是说，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。</p>
<p>这个方法既能享受到 RDB 文件快速恢复的好处，又能享受到 AOF 只记录操作命令的简单优势。</p>
<h3 id="混合使用-AOF-日志和内存快照"><a href="#混合使用-AOF-日志和内存快照" class="headerlink" title="混合使用 AOF 日志和内存快照"></a>混合使用 AOF 日志和内存快照</h3><p>在Redis4.0以前，Redis AOF的重写机制是指令整合，但是在 Redis4.0 以后，Redis 的 AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头，将增量的以指令的方式Append到AOF，这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分就是压缩格式不再是 AOF 格式，可读性较差。Redis服务在读取AOF文件的怎么判断是否AOF文件中是否包含RDB，它会查看是否以 REDIS 开头；人为的看的话，也可以看到以REDIS开头，RDB的文件也打开也是乱码。</p>
<p>可以通过aof-use-rdb-preamble 配置去设置改功能。</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># When rewriting the AOF file, Redis is able to use an RDB preamble in the</span></span><br><span class="line"><span class="comment"># AOF file for faster rewrites and recoveries. When this option is turned</span></span><br><span class="line"><span class="comment"># on the rewritten AOF file is composed of two different stanzas:</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># RDB file</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># When loading Redis recognizes that the AOF file starts with the &quot;REDIS&quot;</span></span><br><span class="line"><span class="comment"># string and loads the prefixed RDB file, and continues loading the AOF</span></span><br><span class="line"><span class="comment"># tail.</span></span><br><span class="line"><span class="meta">aof-use-rdb-preamble</span> <span class="string">yes</span></span><br></pre></td></tr></table></figure>

<h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>关于 AOF 和 RDB 的选择问题，有三点建议：</p>
<ul>
<li>数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择；</li>
<li>如果允许分钟级别的数据丢失，可以只使用 RDB；</li>
<li>如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。</li>
</ul>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>我们使用一个 2 核 CPU、4GB 内存、500GB 磁盘的云主机运行 Redis，Redis 数据库的数据量大小差不多是 2GB，我们使用了 RDB 做持久化保证。当时 Redis 的运行负载以修改操作为主，写读比例差不多在 8:2 左右，也就是说，如果有 100 个请求，80 个请求执行的是修改操作。在这个场景下，用 RDB 做持久化有什么风险吗？</p>
<p>风险主要在于 CPU资源 和 内存资源 这2方面：</p>
<p>a、内存资源风险：Redis fork子进程做RDB持久化，由于写的比例为80%，那么在持久化过程中，“写实复制”会重新分配整个实例80%的内存副本，大约需要重新分配1.6GB内存空间，这样整个系统的内存使用接近饱和，如果此时父进程又有大量新key写入，很快机器内存就会被吃光，如果机器开启了Swap机制，那么Redis会有一部分数据被换到磁盘上，当Redis访问这部分在磁盘上的数据时，性能会急剧下降，已经达不到高性能的标准（可以理解为武功被废）。如果机器没有开启Swap，会直接触发OOM，父子进程会面临被系统kill掉的风险。</p>
<p>b、CPU资源风险：虽然子进程在做RDB持久化，但生成RDB快照过程会消耗大量的CPU资源，虽然Redis处理处理请求是单线程的，但Redis Server还有其他线程在后台工作，例如AOF每秒刷盘、异步关闭文件描述符这些操作。由于机器只有2核CPU，这也就意味着父进程占用了超过一半的CPU资源，此时子进程做RDB持久化，可能会产生CPU竞争，导致的结果就是父进程处理请求延迟增大，子进程生成RDB快照的时间也会变长，整个Redis Server性能下降。</p>
<p>c、另外，可以再延伸一下，老师的问题没有提到Redis进程是否绑定了CPU，如果绑定了CPU，那么子进程会继承父进程的CPU亲和性属性，子进程必然会与父进程争夺同一个CPU资源，整个Redis Server的性能必然会受到影响！所以如果Redis需要开启定时RDB和AOF重写，进程一定不要绑定CPU。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://sevncz.xyz/2020/12/15/Hive%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%8F%8A%E4%BC%98%E5%8C%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/IMG_1169.JPG">
      <meta itemprop="name" content="sevncz">
      <meta itemprop="description" content="努力赚钱">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sevncz's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/12/15/Hive%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%8F%8A%E4%BC%98%E5%8C%96/" class="post-title-link" itemprop="url">Hive文件存储及优化</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-12-15 11:48:56" itemprop="dateCreated datePublished" datetime="2020-12-15T11:48:56+08:00">2020-12-15</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2020-12-22 22:40:15" itemprop="dateModified" datetime="2020-12-22T22:40:15+08:00">2020-12-22</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>最近在做大数据项目上线准备，需要知道Hive性能消耗情况，而我们数据仓库在建设使用的过程中，主要消耗的资源包含：CPU、MEMORY、DISK三部分。</p>
<p>数据仓库在计算过程中主要消耗CPU和Memory资源，当然也会消耗一些DISK资源用来存储计算过程中的临时结果。但是主要优化的方向，还是降低CPU和MEMORY的消耗，这方面主要依赖于模型设计的合理性，所以在模型设计阶段增加模型设计review的步骤，保证模型设计的合理性。</p>
<p>数据仓库在数据的存储阶段主要消耗MEMORY和DISK资源。memory资源主要是在NameNode存储文件信息的时候消耗掉；DISK在存储数据的时候消耗掉。在这个阶段需要严格控制HIVE表的的定义，来降低资源的消耗。</p>
<p>本次主要探讨是数据仓库在数据存储阶段对资源消耗的优化，下面将通过2个方面展开，分别是：数据仓库如何配置，可以实现数据压缩，降低数据的存储量，达到减少对DISK的消耗；数仓表如何设计，可以降低文件信息存储量，达到减少对MEMORY的消耗。</p>
<h2 id="小文件问题"><a href="#小文件问题" class="headerlink" title="小文件问题"></a>小文件问题</h2><p>Hive的数据最终是存储在HDFS上，HDFS的NameNode会保存文件的元数据，为了提高响应速度，NameNode在启动的时候会将这些元数据加载到内存，而HDFS中的每一个文件、目录及文件块，在NameNode内存都会记录，每一条信息大约占用150字节的内存空间。如果HDFS 上存在大量的小文件（这里说的小文件是指文件大小要比一个 HDFS 块大小(在 Hadoop1.x 的时候默认块大小64M，可以通过 dfs.blocksize 来设置；但是到了 Hadoop 2.x 的时候默认块大小为128MB了，可以通过 dfs.block.size 设置) 小得多的文件）至少会产生以下几个负面影响：</p>
<ul>
<li>大量的小文件会占用大量的NameNode内存，一个元数据对象大约占用150个字节，一千万文件及分块就大约 会占用3G的内存空间；</li>
<li>如果使用MapReduce任务来处理这些小文件，因为每一个Map会处理一个HDFS Block，这会导致程序需要启动大量的Map来处理这些小文件，虽然这些小文件总的大小不算很大，却占用了集群的大量资源。</li>
</ul>
<h2 id="Hive小文件产生的原因"><a href="#Hive小文件产生的原因" class="headerlink" title="Hive小文件产生的原因"></a>Hive小文件产生的原因</h2><ul>
<li>MapReduce任务产生：我们使用 Hive 查询一张含有海量数据的表，然后存储在另外一张表中，而这个查询只有简单的过滤条件（比如 select * from iteblog where from = ‘hadoop’），这种情况只会启动大量的 Map 来处理，这种情况可能会产生大量的小文件。也可能 Reduce 设置不合理，产生大量的小文件；</li>
<li>Hive统计汇总表，越是上层的表汇总程度就越高，数据量也就越小，而且这些表通常会有日期分区，随着时间的推移，HDFS的文件数目就会逐步增加；</li>
</ul>
<h2 id="小文件问题解决"><a href="#小文件问题解决" class="headerlink" title="小文件问题解决"></a>小文件问题解决</h2><ul>
<li><p>输入合并。即在map前合并小文件。</p>
</li>
<li><p>输出合并。即在输出结果的时候合并小文件。</p>
</li>
</ul>
<h3 id="1-配置Map输入合并"><a href="#1-配置Map输入合并" class="headerlink" title="1. 配置Map输入合并"></a>1. 配置Map输入合并</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-- 每个Map最大输入大小，决定合并后的文件数</span><br><span class="line">set mapred.max.split.size=256000000;</span><br><span class="line">-- 一个节点上split的至少的大小 ，决定了多个data node上的文件是否需要合并</span><br><span class="line">set mapred.min.split.size.per.node=100000000;</span><br><span class="line">-- 一个交换机下split的至少的大小，决定了多个交换机上的文件是否需要合并</span><br><span class="line">set mapred.min.split.size.per.rack=100000000;</span><br><span class="line">-- 执行Map前进行小文件合并</span><br><span class="line">set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;</span><br></pre></td></tr></table></figure>

<h3 id="2-配置Hive结果合并"><a href="#2-配置Hive结果合并" class="headerlink" title="2. 配置Hive结果合并"></a>2. 配置Hive结果合并</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">set hive.merge.mapfiles = true #在Map-only的任务结束时合并小文件</span><br><span class="line">set hive.merge.mapredfiles = true #在Map-Reduce的任务结束时合并小文件</span><br><span class="line">set hive.merge.size.per.task = 256*1000*1000 #合并文件的大小</span><br><span class="line">set hive.merge.smallfiles.avgsize=16000000 #当输出文件的平均大小小于该值时，启动一个独立的map-reduce任务进行文件merge</span><br></pre></td></tr></table></figure>

<p>hive在对结果文件进行合并时会执行一个额外的map-only脚本，mapper的数量是文件总大小除以size.per.task参数所得的值，触发合并的条件是：根据查询类型不同，相应的mapfiles/mapredfiles参数需要打开；结果文件的平均大小需要大于avgsize参数的值。</p>
<h3 id="3-压缩文件的处理"><a href="#3-压缩文件的处理" class="headerlink" title="3. 压缩文件的处理"></a>3. 压缩文件的处理</h3><p>对于输出结果为压缩文件形式存储的情况，要解决小文件问题，如果在map输入前合并，对输出的文件存储格式并没有限制。但是如果使用输出合并，则必须配合SequenceFile来存储，否则无法进行合并，以下是实例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> mapred.output.compression.type=<span class="keyword">BLOCK</span>;</span><br><span class="line"><span class="keyword">set</span> hive.exec.compress.output= <span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> mapred.output.compression.codec=org.apache.hadoop.io.compress.LzoCodec;</span><br><span class="line"><span class="keyword">set</span> hive.merge.smallfiles.avgsize=<span class="number">100000000</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> dw_stage.zj_small;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> dw_stage.zj_small</span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> SEQUENCEFILE</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> *</span><br><span class="line"><span class="keyword">from</span> dw_db.dw_soj_imp_dtl</span><br><span class="line"><span class="keyword">where</span> log_dt = <span class="string">&#x27;2014-04-14&#x27;</span></span><br><span class="line"><span class="keyword">and</span> paid <span class="keyword">like</span> <span class="string">&#x27;%baidu%&#x27;</span> ;</span><br></pre></td></tr></table></figure>

<h3 id="4-使用HAR归档文件"><a href="#4-使用HAR归档文件" class="headerlink" title="4. 使用HAR归档文件"></a>4. 使用HAR归档文件</h3><p>Hadoop的归档文件格式也是解决小文件问题的方式之一。而且hive提供了原生支持：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.archive.enabled= <span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> hive.archive.har.parentdir.settable= <span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> har.partfile.size=<span class="number">1099511627776</span>;</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> srcpart <span class="keyword">ARCHIVE</span> <span class="keyword">PARTITION</span>(ds= <span class="string">&#x27;2008-04-08&#x27;</span>, hr= <span class="string">&#x27;12&#x27;</span> );</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> srcpart UNARCHIVE <span class="keyword">PARTITION</span>(ds= <span class="string">&#x27;2008-04-08&#x27;</span>, hr= <span class="string">&#x27;12&#x27;</span> );</span><br></pre></td></tr></table></figure>

<p>如果使用的不是分区表，则可以创建成外部表，并使用har://协议来指定路径。</p>
<h2 id="文件类型"><a href="#文件类型" class="headerlink" title="文件类型"></a>文件类型</h2><p>hive在存储数据时支持通过不同的文件类型来组织，并且为了节省相应的存储资源，也提供了多种类型的压缩算法，供用户选择。只要是配置正确的文件类型和压缩类型，hive都可以按预期读取并解析数据，不影响上层HQL语句的使用。例如：SequenceFile本身的结构已经设计了对内容进行压缩，所以对于SequenceFile文件的压缩，并不是先生成SequenceFile文件，再对文件进行压缩；而是生成SequenceFile文件时，就对其中的内容字段进行压缩。最终压缩后，对外仍然体现为一个SequenceFile。RCFile、ORCFile、Parquet、Avro对于压缩的处理方式与SequenceFile相同。</p>
<p>hive支持的文件类型有：TextFile、SequenceFile、RCFile、ORCFile、Parquet、Avro。</p>
<table>
  <tr>
    <th>存储格式</td>
    <th>存储方式</td>
    <th>特点</td>
  </tr>
  <tr>
    <td rowspan="5">TextFile</td>
    <td rowspan="5">行存储</td>
    <td>存储空间消耗比较大</td>
  </tr>
  <tr>
    <td>压缩的text无法分割和合并</td>
  </tr>
  <tr>
    <td>查询效率低</td>
  </tr>
  <tr>
    <td>可以直接存储</td>
  </tr>
  <tr>
    <td>加载数据速度最高</td>
  </tr>
  <tr>
    <td rowspan="4">SequenceFile</td>
    <td rowspan="4">行存储</td>
    <td>存储空间消耗最大</td>
  </tr>
  <tr>
    <td>压缩的文件可以分割和合并</td>
  </tr>
  <tr>
    <td>查询效率高</td>
  </tr>
  <tr>
    <td>需要通过text文件转化来加载</td>
  </tr>
  <tr>
    <td rowspan="8">RCFile</td>
    <td rowspan="8">数据按行分块，每块按列存储</td>
    <td>存储空间最小</td>
  </tr>
  <tr>
    <td>查询效率最高</td>
  </tr>
  <tr>
    <td>需要通过text文件转化来加载</td>
  </tr>
  <tr>
    <td>加载的速度最低</td>
  </tr>
  <tr>
    <td>压缩快，快速列存储</td>
  </tr>
  <tr>
    <td>读记录尽量设计到的block最少</td>
  </tr>
  <tr>
    <td>读取需要的列只需要读取每个row group的头部定义</td>
  </tr>
  <tr>
    <td>读取全量数据的操作性能可能比sequencefile没有明显的优势</td>
  </tr>
  <tr>
    <td rowspan="2">ORCFile</td>
    <td rowspan="2">数据按行分块，每块按列存储</td>
    <td>压缩快，快速列存储</td>
  </tr>
  <tr>
    <td>效率比RCFile高，是RCFile的改良版</td>
  </tr>
  <tr>
    <td rowspan="4">Parquet</td>
    <td rowspan="4">列存储</td>
    <td>相对于PRC，Parquet压缩比较低</td>
  </tr>
  <tr>
    <td>查询效率比较低</td>
  </tr>
  <tr>
    <td>不支持update、insert和ACID</td>
  </tr>
  <tr>
    <td>支持Impala查询引擎</td>
  </tr>
  <tr>
    <td rowspan="5">Avro</td>
    <td rowspan="5">二进制存储</td>
    <td>基于列(在列中存储数据):用于数据存储是包含大量读取操作的优化分析工作负载</td>
  </tr>
  <tr>
    <td>与Snappy的压缩压缩率高(75%)</td>
  </tr>
  <tr>
    <td>只需要列将获取/读(减少磁盘I / O)</td>
  </tr>
  <tr>
    <td>可以使用Avro API和Avro读写模式</td>
  </tr>
  <tr>
    <td>支持谓词下推(减少磁盘I / O的成本)</td>
  </tr>
</table>

<h2 id="压缩算法"><a href="#压缩算法" class="headerlink" title="压缩算法"></a>压缩算法</h2><p>待补充</p>
<h2 id="表分区优化"><a href="#表分区优化" class="headerlink" title="表分区优化"></a>表分区优化</h2><ul>
<li>对于统计数据表、数据量不大的基础表、业务上无累计快照和周期性快照要求的数据表，尽可能的不创建分区，而采用数据合并回写的方式解决；</li>
<li>对于一些数据量大的表，如果需要创建分区，提高插叙过程中数据的加载速度，尽可能的只做天级分区。而对于原始数据，这种特大的数据量的，可以采用小时分区。对于月分区，坚决去掉。</li>
<li>对于一些周期快照和累计快照的表，我们尽可能只创建日分区。</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://sevncz.xyz/2020/12/15/Redis%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/IMG_1169.JPG">
      <meta itemprop="name" content="sevncz">
      <meta itemprop="description" content="努力赚钱">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sevncz's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/12/15/Redis%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" class="post-title-link" itemprop="url">Redis底层数据结构</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-12-15 10:01:35" itemprop="dateCreated datePublished" datetime="2020-12-15T10:01:35+08:00">2020-12-15</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2020-12-22 22:39:51" itemprop="dateModified" datetime="2020-12-22T22:39:51+08:00">2020-12-22</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Redis/" itemprop="url" rel="index"><span itemprop="name">Redis</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>一提到 Redis，我们的脑子里马上就会出现一个词：“快”，这里的快，体现在Redis接收到一个键值对操作后，能以微秒级别的速度找到数据，并快速完成操作。那，为什么这么快呢？一方面，这是因为它是内存数据库，所有的操作都是在内存上完成，内存的访问速度本身就很快。另一方面，这要归功于它的数据结构，这是因为，键值对是按一定的数据结构来阻止的，操作键值对最终就是对数据结构进行增删改查操作，所以高效的数据结构是Redis快速处理数据的基础。</p>
<h2 id="六种底层数据结构"><a href="#六种底层数据结构" class="headerlink" title="六种底层数据结构"></a>六种底层数据结构</h2><p>Redis的底层数据结构一共有6中，分别是简单动态字符串、双向链表、压缩列表、哈希表、跳表和整数数组。</p>
<p>Redis的数据类型和底层数据结构的关系：</p>
<ul>
<li>String：简单动态字符串</li>
<li>List：双向链表、压缩列表</li>
<li>Hash：压缩列表、哈希表</li>
<li>Sorted Set：压缩列表、跳表</li>
<li>Set：哈希表、整数数组</li>
</ul>
<p>这里，我们会遇到如下几个问题：</p>
<ol>
<li>这些数据结构都是值的底层实现，键和值本身之间用什么结构组织？</li>
<li>为什么集合类型有那么多的底层结构，它们都是怎么组织数据的，都很快吗？</li>
<li>什么是简单动态字符串，和常用的字符串是一回事吗？</li>
</ol>
<h2 id="键和值用什么结构组织"><a href="#键和值用什么结构组织" class="headerlink" title="键和值用什么结构组织"></a>键和值用什么结构组织</h2><p>为了实现从键到值的快速访问，Redis 使用了一个哈希表来保存所有的键值对。</p>
<p>一个哈希表，其实就是一个数组，数组的每个元素称为一个哈希桶。所以，我们常说一个哈希表是由多个哈希桶组成，每个哈希桶中保存了键值对数据。哈希桶中并不存键值对本身，而是存键值对指针。因为这个哈希表保存了所有的键值对，所以，我也把它称为全局哈希表。哈希表的好处就是我们能以O(1)的时间复杂度来快速查找到键值对 （我们只需要计算键的哈希值，就可以知道它所对应的哈希桶位置，然后就可以访问相应的 entry 元素）。</p>
<p>当哈希表写入大量的数据之后，就会产生哈希冲突和rehash可能带来的操作阻塞。</p>
<h2 id="哈希冲突问题"><a href="#哈希冲突问题" class="headerlink" title="哈希冲突问题"></a>哈希冲突问题</h2><p>当你往哈希表中写入更多数据时，哈希冲突是不可避免的问题。这里的哈希冲突，也就是指，两个 key 的哈希值和哈希桶计算对应关系时，正好落在了同一个哈希桶中。</p>
<p>Redis 解决哈希冲突的方式，就是链式哈希。链式哈希，就是指同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接。</p>
<h2 id="rehash"><a href="#rehash" class="headerlink" title="rehash"></a>rehash</h2><p>随着哈希表里写入的数据越来越多，哈希冲突可能也会越来越多，这就会导致某些哈希冲突链过长，进而导致这个链上的元素查找耗时长，效率降低。这时，Redis会对哈希表做rehash操作。rehash也就是增加现有的哈希桶数量，让逐渐增多的entry元素能在更多的桶之间分散保存，减少单个桶的元素数量，从而减少单个桶的冲突。</p>
<p>具体做法：为了使rehash操作更高效，Redis默认使用了两个全局哈希表：哈希表1和哈希表2。一开始，当你插入数据时，默认会使用哈希表1，此时的哈希表2并没有分配空间，随着数据逐步增多，Redis开始进行rehash，这个过程分为3步：</p>
<ol>
<li>给哈希表2分配更多的空间，例如时当前哈希表1大小的2倍；</li>
<li>把哈希表1中的数据重新映射并拷贝到哈希表2中；</li>
<li>释放哈希表1的空间。</li>
</ol>
<p>到此，就可以从哈希表 1 切换到哈希表 2，用增大的哈希表 2 保存更多数据，而原来的哈希表 1 留作下一次 rehash 扩容备用。</p>
<p>这个过程看似简单，但是第二步涉及到大量的数据拷贝，如果一次性把哈希表1中的数据都迁移完，会造成Redis线程阻塞，无法服务其他请求。</p>
<p>为了避免这个问题，Redis采用了<strong>渐进式rehash</strong>。</p>
<p>简单来说就是第二步拷贝数据时，Redis仍然正常处理客户端请求，每处理一个请求时，从哈希表1中的第一个索引位置开始，顺带着将这个索引位置上的所有entry拷贝到哈希表2中；等处理下一个请求时，再顺带拷贝哈希表1中下一个索引位置的entry。这样就巧妙地把一次性大量拷贝的开销，分摊到了多次处理请求的过程中，避免了耗时操作，保证了数据的快速访问。</p>
<p>对于String类型来说，找到哈希桶就能直接增删改查了，所以哈希表O(1)操作复杂度也就是它的复杂度了。</p>
<p>对于集合类型来说，即使找到哈希桶了，还要在集合中再进一步操作。</p>
<h2 id="集合数据操作"><a href="#集合数据操作" class="headerlink" title="集合数据操作"></a>集合数据操作</h2><p>和 String 类型不同，一个集合类型的值，第一步是通过全局哈希表找到对应的哈希桶位置，第二步是在集合中再增删改查。那么，集合的操作效率和哪些因素相关呢？</p>
<p>首先，与集合的底层数据结构有关。例如，使用哈希表实现的集合，要比使用链表实现的集合访问效率更高。其次，操作效率和这些操作本身的执行特点有关，比如读写一个元素的操作要比读写所有元素的效率高。</p>
<h3 id="有哪些底层数据结构"><a href="#有哪些底层数据结构" class="headerlink" title="有哪些底层数据结构"></a>有哪些底层数据结构</h3><p>集合类型的底层数据结构主要有 5 种：整数数组、双向链表、哈希表、压缩列表和跳表。</p>
<p>哈希表的操作特点如上文所述，整数数组和双向链表也很常见，它们的操作特征都是顺序读写，也就是通过数组下标或者链表的指针逐个元素访问，操作复杂度基本时O(N)，操作效率比较低；</p>
<h4 id="压缩列表"><a href="#压缩列表" class="headerlink" title="压缩列表"></a>压缩列表</h4><p>压缩列表实际上类似于一个数组，数组中的每一个元素都对应保存一个数据。和数组不同的是，压缩列表在表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量和列表中的 entry 个数；压缩列表在表尾还有一个 zlend，表示列表结束。</p>
<p>在压缩列表中，如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是 O(1)。而查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是 O(N) 了。</p>
<h4 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h4><p>有序链表只能逐一查找元素，导致操作起来非常缓慢，于是就出现了跳表。具体来说，跳表在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位，</p>
<h2 id="不同的操作复杂度"><a href="#不同的操作复杂度" class="headerlink" title="不同的操作复杂度"></a>不同的操作复杂度</h2><p>集合类型的操作类型很多，有读写单个集合元素的，例如 HGET、HSET，也有操作多个元素的，例如 SADD，还有对整个集合进行遍历操作的，例如 SMEMBERS。这么多操作，它们的复杂度也各不相同。而复杂度的高低又是我们选择集合类型的重要依据。</p>
<ul>
<li>单元素操作是基础；</li>
<li>范围操作非常耗时；</li>
<li>统计操作通常高效；</li>
<li>例外情况只有几个。</li>
</ul>
<p>第一，单元素操作，是指每一种集合类型对单个数据实现的增删改查操作。例如，Hash 类型的 HGET、HSET 和 HDEL，Set 类型的 SADD、SREM、SRANDMEMBER 等。这些操作的复杂度由集合采用的数据结构决定，例如，HGET、HSET 和 HDEL 是对哈希表做操作，所以它们的复杂度都是 O(1)；Set 类型用哈希表作为底层数据结构时，它的 SADD、SREM、SRANDMEMBER 复杂度也是 O(1)。</p>
<p>这里，有个地方你需要注意一下，集合类型支持同时对多个元素进行增删改查，例如 Hash 类型的 HMGET 和 HMSET，Set 类型的 SADD 也支持同时增加多个元素。此时，这些操作的复杂度，就是由单个元素操作复杂度和元素个数决定的。例如，HMSET 增加 M 个元素时，复杂度就从 O(1) 变成 O(M) 了。</p>
<p>第二，范围操作，是指集合类型中的遍历操作，可以返回集合中的所有数据，比如 Hash 类型的 HGETALL 和 Set 类型的 SMEMBERS，或者返回一个范围内的部分数据，比如 List 类型的 LRANGE 和 ZSet 类型的 ZRANGE。这类操作的复杂度一般是 O(N)，比较耗时，我们应该尽量避免。不过，Redis 从 2.8 版本开始提供了 SCAN 系列操作（包括 HSCAN，SSCAN 和 ZSCAN），这类操作实现了渐进式遍历，每次只返回有限数量的数据。这样一来，相比于 HGETALL、SMEMBERS 这类操作来说，就避免了一次性返回所有元素而导致的 Redis 阻塞。</p>
<p>第三，统计操作，是指集合类型对集合中所有元素个数的记录，例如 LLEN 和 SCARD。这类操作复杂度只有 O(1)，这是因为当集合类型采用压缩列表、双向链表、整数数组这些数据结构时，这些结构中专门记录了元素的个数统计，因此可以高效地完成相关操作。</p>
<p>第四，例外情况，是指某些数据结构的特殊记录，例如压缩列表和双向链表都会记录表头和表尾的偏移量。这样一来，对于 List 类型的 LPOP、RPOP、LPUSH、RPUSH 这四个操作来说，它们是在列表的头尾增删元素，这就可以通过偏移量直接定位，所以它们的复杂度也只有 O(1)，可以实现快速操作。</p>
<h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>整数数组和压缩列表在查找时间复杂度方面并没有很大的优势，那为什么 Redis 还会把它们作为底层数据结构呢？</p>
<p>1、内存利用率，数组和压缩列表都是非常紧凑的数据结构，它比链表占用的内存要更少。Redis是内存数据库，大量数据存到内存中，此时需要做尽可能的优化，提高内存的利用率。 </p>
<p>2、数组对CPU高速缓存支持更友好，所以Redis在设计时，集合数据元素较少情况下，默认采用内存紧凑排列的方式存储，同时利用CPU高速缓存不会降低访问速度。当数据元素超过设定阈值后，避免查询时间复杂度太高，转为哈希和跳表数据结构存储，保证查询效率。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://sevncz.xyz/2020/12/14/Spark%20Streaming%E8%BF%90%E8%A1%8C%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/IMG_1169.JPG">
      <meta itemprop="name" content="sevncz">
      <meta itemprop="description" content="努力赚钱">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sevncz's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/12/14/Spark%20Streaming%E8%BF%90%E8%A1%8C%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/" class="post-title-link" itemprop="url">Spark Streaming运行的基本原理</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-12-14 13:43:00" itemprop="dateCreated datePublished" datetime="2020-12-14T13:43:00+08:00">2020-12-14</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2020-12-22 22:40:58" itemprop="dateModified" datetime="2020-12-22T22:40:58+08:00">2020-12-22</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Spark Streaming运行时由Driver和Executor相互协调完成。</p>
<p>Driver端创建<strong>StreamingContent</strong>，其中包括了<strong>DStreamGraph</strong>和<strong>JobSchedule</strong>，它又包括了<strong>ReceiverTracker</strong>和<strong>JobGenerator</strong>），Driver主要负责生成调度job、与execuor进行交互、指导工作。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://sevncz.xyz/2020/12/14/%E8%AE%B0%E4%B8%80%E6%AC%A1Mac%E5%A4%84%E7%90%86%E6%96%87%E4%BB%B6%E6%97%A0%E6%B3%95%E5%88%A0%E9%99%A4%E6%93%8D%E4%BD%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/IMG_1169.JPG">
      <meta itemprop="name" content="sevncz">
      <meta itemprop="description" content="努力赚钱">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sevncz's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/12/14/%E8%AE%B0%E4%B8%80%E6%AC%A1Mac%E5%A4%84%E7%90%86%E6%96%87%E4%BB%B6%E6%97%A0%E6%B3%95%E5%88%A0%E9%99%A4%E6%93%8D%E4%BD%9C/" class="post-title-link" itemprop="url">记一次Mac处理文件无法删除操作</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-12-14 10:34:43" itemprop="dateCreated datePublished" datetime="2020-12-14T10:34:43+08:00">2020-12-14</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2020-12-22 22:40:42" itemprop="dateModified" datetime="2020-12-22T22:40:42+08:00">2020-12-22</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Mac/" itemprop="url" rel="index"><span itemprop="name">Mac</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="处理流程"><a href="#处理流程" class="headerlink" title="处理流程"></a>处理流程</h2><p>安装了公司的安全上网软件，但是无法卸载和删除。</p>
<p>执行rm -rf无法删除</p>
<img src="/2020/12/14/%E8%AE%B0%E4%B8%80%E6%AC%A1Mac%E5%A4%84%E7%90%86%E6%96%87%E4%BB%B6%E6%97%A0%E6%B3%95%E5%88%A0%E9%99%A4%E6%93%8D%E4%BD%9C/image-20201214103807333.png" class="">

<p><code>ls -lO</code>查看权限</p>
<img src="/2020/12/14/%E8%AE%B0%E4%B8%80%E6%AC%A1Mac%E5%A4%84%E7%90%86%E6%96%87%E4%BB%B6%E6%97%A0%E6%B3%95%E5%88%A0%E9%99%A4%E6%93%8D%E4%BD%9C/image-20201214103914978.png" class="">

<p>需要清理这两个标记</p>
<p>执行：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo chflags -R nohidden [文件夹名称]</span><br><span class="line">sudo chflags -R noschg [文件夹名称]</span><br><span class="line">sudo chmod -R +w [文件夹名称]</span><br><span class="line">sudo chmod -R +r [文件夹名称]</span><br></pre></td></tr></table></figure>

<p>最后</p>
<img src="/2020/12/14/%E8%AE%B0%E4%B8%80%E6%AC%A1Mac%E5%A4%84%E7%90%86%E6%96%87%E4%BB%B6%E6%97%A0%E6%B3%95%E5%88%A0%E9%99%A4%E6%93%8D%E4%BD%9C/image-20201214104224717.png" class="">

<h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><p><code>ls</code>的<code>-O</code>选项，可以列出文件的file flag。</p>
<h3 id="File-Flag"><a href="#File-Flag" class="headerlink" title="File Flag"></a>File Flag</h3><p>File flag是在BSD Unix中的概念，跟Linux系统中的attr是差不多的一个概念，是文件的一些标志位来存放文件的某些属性。chflags就是来修改这个file flag的。这个文件属性是跟文件系统相关的，所以这个命令在不同的文件系统上的支持程度不一样，体现在某一些flag在一些特定的文件系统上没有。</p>
<h3 id="常见的几个属性"><a href="#常见的几个属性" class="headerlink" title="常见的几个属性"></a>常见的几个属性</h3><table>
<thead>
<tr>
<th align="left">属性</th>
<th align="left">ls中显示</th>
<th align="left">chflags中使用</th>
<th align="left">文件所有者能否修改</th>
<th align="left">详述</th>
</tr>
</thead>
<tbody><tr>
<td align="left">隐藏</td>
<td align="left">hidden</td>
<td align="left">hidden</td>
<td align="left">能</td>
<td align="left">设置以后在GUI上看不到，ls依然可以看到d</td>
</tr>
<tr>
<td align="left">系统级只能添加</td>
<td align="left">sappnd</td>
<td align="left">sappnd, sappend</td>
<td align="left">否</td>
<td align="left">设置以后此文件不能够截断或者复写(overwrite)，只能通过append模式添加内容</td>
</tr>
<tr>
<td align="left">用户级只能添加</td>
<td align="left">uappnd</td>
<td align="left">uappnd, uappend</td>
<td align="left">能</td>
<td align="left">设置以后此文件不能够截断或者复写(overwrite)，只能通过append模式添加内容</td>
</tr>
<tr>
<td align="left">系统级只读</td>
<td align="left">schg</td>
<td align="left">schg, schange, simmutable</td>
<td align="left">否</td>
<td align="left">不能够重命名、移动、删除、更改内容</td>
</tr>
<tr>
<td align="left">用户级只读</td>
<td align="left">uchg</td>
<td align="left">uchg, uchange, uimmutable</td>
<td align="left">能</td>
<td align="left">不能够更改内容</td>
</tr>
</tbody></table>
<h3 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h3><p><code>chflags [-fhv] [-R [-H | -L | -P]] flags file</code></p>
<h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><p><strong>为一个文件添加一个属性</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chflags uchg file</span><br></pre></td></tr></table></figure>

<p><strong>为一个文件删除一个属性</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chflags nouchg file</span><br></pre></td></tr></table></figure>

<p>在属性名字前面添加no就可以将属性删除，如果这个属性本身已no开头（比如nodump）则去掉no。</p>
<p><strong>将文件夹及其文件夹下所有文件属性进行修改</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chflags -R uchg directory</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>


<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">sevncz@xyz</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  







  






</body>
</html>
